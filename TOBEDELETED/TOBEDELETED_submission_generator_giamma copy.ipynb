{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ee26eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from config.regressors import VotingRegressor, StackingRegressor, NNRegressor\n",
    "\n",
    "from config.models import ConvNN\n",
    "\n",
    "from config.loss_functions import RMSELoss\n",
    "\n",
    "import pyriemann\n",
    "import pyriemann.regression\n",
    "\n",
    "from config.transformers import TimeDomainTransformer, TimeWindowTransformer, LabelWindowExtractor, WaveletFeatureTransformer\n",
    "from config.validation import RMSE, NMSE, cross_validate_pipeline, cross_validate_NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ea8cb9",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455d5401",
   "metadata": {},
   "source": [
    "### Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52f725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Combine features\n",
    "# Define your base feature extractors\n",
    "time_feat = ('time_features', TimeDomainTransformer(sigma_mpr=0.3))\n",
    "wavelet_feat = ('wavelet_features', WaveletFeatureTransformer())\n",
    "\n",
    "combined_features = FeatureUnion([\n",
    "    time_feat,\n",
    "    wavelet_feat\n",
    "])\n",
    "\n",
    "# Wrap with session-wise transformer\n",
    "sessionwise_combined = SessionwiseTransformer(combined_features)\n",
    "\n",
    "baseline_guided_kr = Pipeline([\n",
    "    ('feature_extraction', sessionwise_combined),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=float(0.9), random_state=42)),\n",
    "    ('regressor', KernelRidge(\n",
    "        alpha=0.01,\n",
    "        gamma=0.01,\n",
    "        kernel='rbf'\n",
    "    ))\n",
    "])\n",
    "\n",
    "baseline_guided_knn = Pipeline([\n",
    "    ('feature_extraction', sessionwise_combined),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=float(0.9), random_state=42)),\n",
    "    ('regressor', KNeighborsRegressor(n_neighbors=5))\n",
    "])\n",
    "\n",
    "baseline_guided_rf = Pipeline([\n",
    "    ('feature_extraction', sessionwise_combined),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('pca', PCA(n_components=float(0.9), random_state=42)),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=50, max_depth=10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36c566c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_guided_kr = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', TimeDomainTransformer(sigma_mpr=0.3)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', KernelRidge(\n",
    "            alpha = 0.01,\n",
    "            gamma = 0.01,\n",
    "            kernel='laplacian'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "baseline_guided_knn = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', TimeDomainTransformer(sigma_mpr=0.3)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', KNeighborsRegressor(\n",
    "            n_neighbors = 7))\n",
    "    ]\n",
    ")\n",
    "\n",
    "baseline_guided_rf = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', TimeDomainTransformer(sigma_mpr=0.3)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', RandomForestRegressor(\n",
    "            n_estimators = 50,\n",
    "            max_depth = 10))\n",
    "    ]\n",
    ")\n",
    "\n",
    "timedomain_xgboost = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', TimeDomainTransformer(sigma_mpr=0.3)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', XGBRegressor(\n",
    "            n_estimators = 100,\n",
    "            max_depth = 5,\n",
    "            learning_rate = 0.1,\n",
    "            objective='reg:squarederror',\n",
    "            n_jobs=-1,\n",
    "            verbosity=1\n",
    "        ))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0785ada4",
   "metadata": {},
   "source": [
    "### Riemannian models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c84f91d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riemannian geometry of covariance matrices\n",
    "riem1 = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', pyriemann.estimation.Covariances()),\n",
    "        ('transformation', pyriemann.tangentspace.TangentSpace(\n",
    "            metric = 'riemann',\n",
    "            tsupdate = True)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', KernelRidge(\n",
    "            alpha = 0.01,\n",
    "            gamma = 0.01,\n",
    "            kernel='laplacian'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "riem2 = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', pyriemann.estimation.Covariances()),\n",
    "        ('transformation', pyriemann.tangentspace.TangentSpace(\n",
    "            metric = 'riemann',\n",
    "            tsupdate = True)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', KNeighborsRegressor(\n",
    "            n_neighbors = 7))\n",
    "    ]\n",
    ")\n",
    "\n",
    "riem3 = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', pyriemann.estimation.Covariances()),\n",
    "        ('transformation', pyriemann.tangentspace.TangentSpace(\n",
    "            metric = 'riemann',\n",
    "            tsupdate = True)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', RandomForestRegressor(\n",
    "            n_estimators = 50,\n",
    "            max_depth = 10))\n",
    "    ]\n",
    ")\n",
    "\n",
    "riem4 = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', pyriemann.estimation.Covariances()),\n",
    "        ('transformation', pyriemann.tangentspace.TangentSpace(\n",
    "            metric = 'riemann',\n",
    "            tsupdate = True)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', XGBRegressor(\n",
    "            n_estimators = 100,\n",
    "            max_depth = 5,\n",
    "            learning_rate = 0.1,\n",
    "            objective='reg:squarederror',\n",
    "            n_jobs=-1,\n",
    "            verbosity=1\n",
    "        ))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed2284",
   "metadata": {},
   "source": [
    "### Ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6488776",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_estimator = VotingRegressor(\n",
    "    estimators = [\n",
    "        baseline_guided_kr,\n",
    "        baseline_guided_knn,\n",
    "        baseline_guided_rf,\n",
    "        timedomain_xgboost,\n",
    "        riem1,\n",
    "        riem2,\n",
    "        riem3,\n",
    "        riem4\n",
    "    ]\n",
    ")\n",
    "\n",
    "stacking_estimator = StackingRegressor(\n",
    "    estimators = [\n",
    "        baseline_guided_kr,\n",
    "        # baseline_guided_knn,\n",
    "        # baseline_guided_rf,\n",
    "        timedomain_xgboost,\n",
    "        # riem1,\n",
    "        # riem2,\n",
    "        # riem3,\n",
    "        riem4\n",
    "    ],\n",
    "    end_estimator = RandomForestRegressor(\n",
    "        n_estimators = 50,\n",
    "        max_depth = 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae29bf95",
   "metadata": {},
   "source": [
    "# Final generalization evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d464e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = f'/Users/marco/PROJECTS/data/'\n",
    "PATH = r'C:\\Users\\gianm\\Documents\\Uni\\Big Data\\F422\\project\\data\\\\'\n",
    "\n",
    "# model = baseline_guided_kr\n",
    "step = 250\n",
    "\n",
    "metric_fns = {'RMSE': RMSE, 'NMSE': NMSE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a016181",
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_extractor = TimeWindowTransformer(size = 500, step = step)\n",
    "label_extractor = LabelWindowExtractor(size = 500, step = step)\n",
    "\n",
    "# guided\n",
    "X_guided = np.load(PATH + f'guided/guided_dataset_X.npy')\n",
    "Y_guided = np.load(PATH + f'guided/guided_dataset_Y.npy')\n",
    "X_guided_windows = tw_extractor.transform(X_guided)\n",
    "Y_guided_labels = label_extractor.transform(Y_guided)\n",
    "\n",
    "# freemoves\n",
    "X_freemoves = np.load(PATH + f'freemoves/freemoves_dataset_X.npy')\n",
    "Y_freemoves = np.load(PATH + f'freemoves/freemoves_dataset_Y.npy')\n",
    "X_freemoves_windows = tw_extractor.transform(X_freemoves)\n",
    "Y_freemoves_labels = label_extractor.transform(Y_freemoves)\n",
    "\n",
    "# # stacked\n",
    "# X_stacked_windows = np.concatenate([X_guided_windows, X_freemoves_windows], axis=1)\n",
    "# Y_stacked_labels = np.concatenate([Y_guided_labels, Y_freemoves_labels], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b5bb091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-domain feature shape: (5, 1079, 8, 500)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 11\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTime-domain feature shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_freemoves_windows\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# (n_windows, td_features)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m riem_pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m      5\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeature_extraction\u001b[39m\u001b[38;5;124m'\u001b[39m, pyriemann\u001b[38;5;241m.\u001b[39mestimation\u001b[38;5;241m.\u001b[39mCovariances()),\n\u001b[0;32m      6\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformation\u001b[39m\u001b[38;5;124m'\u001b[39m, pyriemann\u001b[38;5;241m.\u001b[39mtangentspace\u001b[38;5;241m.\u001b[39mTangentSpace(\n\u001b[0;32m      7\u001b[0m         metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mriemann\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m         tsupdate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m      9\u001b[0m ])\n\u001b[1;32m---> 11\u001b[0m X_riem \u001b[38;5;241m=\u001b[39m \u001b[43mriem_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_freemoves_windows\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# shape: (n_windows, riem_features)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRiemannian feature shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_riem\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Step 3: Wavelet features\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gianm\\miniforge3\\envs\\test\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gianm\\miniforge3\\envs\\test\\Lib\\site-packages\\sklearn\\pipeline.py:533\u001b[0m, in \u001b[0;36mPipeline.fit_transform\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model and transform with the final estimator.\u001b[39;00m\n\u001b[0;32m    491\u001b[0m \n\u001b[0;32m    492\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and sequentially transform\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;124;03m    Transformed samples.\u001b[39;00m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    532\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m--> 533\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    535\u001b[0m last_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\n\u001b[0;32m    536\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n",
      "File \u001b[1;32mc:\\Users\\gianm\\miniforge3\\envs\\test\\Lib\\site-packages\\sklearn\\pipeline.py:406\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, routed_params)\u001b[0m\n\u001b[0;32m    404\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    405\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 406\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32mc:\\Users\\gianm\\miniforge3\\envs\\test\\Lib\\site-packages\\joblib\\memory.py:312\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gianm\\miniforge3\\envs\\test\\Lib\\site-packages\\sklearn\\pipeline.py:1310\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[0;32m   1308\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m   1309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1310\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1311\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1312\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[0;32m   1313\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m   1314\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\gianm\\miniforge3\\envs\\test\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\gianm\\miniforge3\\envs\\test\\Lib\\site-packages\\pyriemann\\estimation.py:94\u001b[0m, in \u001b[0;36mCovariances.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     80\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit and transform in a single function.\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03m        Covariance matrices.\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gianm\\miniforge3\\envs\\test\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    322\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\gianm\\miniforge3\\envs\\test\\Lib\\site-packages\\pyriemann\\estimation.py:76\u001b[0m, in \u001b[0;36mCovariances.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m     64\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Estimate covariance matrices.\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m        Covariance matrices.\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 76\u001b[0m     covmats \u001b[38;5;241m=\u001b[39m \u001b[43mcovariances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m covmats\n",
      "File \u001b[1;32mc:\\Users\\gianm\\miniforge3\\envs\\test\\Lib\\site-packages\\pyriemann\\utils\\covariance.py:397\u001b[0m, in \u001b[0;36mcovariances\u001b[1;34m(X, estimator, **kwds)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Estimation of covariance matrices.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \n\u001b[0;32m    344\u001b[0m \u001b[38;5;124;03mEstimates covariance matrices from multi-channel time-series according to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m \u001b[38;5;124;03m    Conference on Acoustics, Speech and Signal Processing, Volume 2, 2007.\u001b[39;00m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m    396\u001b[0m est \u001b[38;5;241m=\u001b[39m check_function(estimator, cov_est_functions)\n\u001b[1;32m--> 397\u001b[0m n_matrices, n_channels, n_times \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    398\u001b[0m covmats \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((n_matrices, n_channels, n_channels), dtype\u001b[38;5;241m=\u001b[39mX\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_matrices):\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "# Time-domain features\n",
    "print(\"Time-domain feature shape:\", X_freemoves_windows.shape)  # (n_windows, td_features)\n",
    "\n",
    "riem_pipeline = Pipeline([\n",
    "    ('feature_extraction', pyriemann.estimation.Covariances()),\n",
    "    ('transformation', pyriemann.tangentspace.TangentSpace(\n",
    "        metric = 'riemann',\n",
    "        tsupdate = True))\n",
    "])\n",
    "\n",
    "X_riem = riem_pipeline.fit_transform(X_freemoves_windows)  # shape: (n_windows, riem_features)\n",
    "print(\"Riemannian feature shape:\", X_riem.shape)\n",
    "\n",
    "# Step 3: Wavelet features\n",
    "wave = WaveletFeatureTransformer(summary=True)\n",
    "X_wave = wave.fit_transform(X_freemoves_windows)  # shape: (n_windows, wave_features)\n",
    "print(\"Wavelet feature shape:\", X_wave.shape)\n",
    "\n",
    "# Step 4: Total features\n",
    "total_features = X_freemoves_windows.shape[1] + X_riem.shape[1] + X_wave.shape[1]\n",
    "print(\"Total combined feature dimension:\", total_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb5119d",
   "metadata": {},
   "source": [
    "#### RMSE guided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debe9a8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of weights must be consistent with shape of a along specified axis.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m weights \u001b[38;5;129;01min\u001b[39;00m weight_sets:\n\u001b[0;32m     37\u001b[0m     ensemble \u001b[38;5;241m=\u001b[39m VotingRegressor(estimators\u001b[38;5;241m=\u001b[39mestimators, weights\u001b[38;5;241m=\u001b[39mweights)\n\u001b[1;32m---> 39\u001b[0m     cv_scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensemble\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_guided_windows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_guided_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_fns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_folds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[0;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m     results\u001b[38;5;241m.\u001b[39mappend((weights, cv_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_val_RMSE\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeights: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweights\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m → avg_val_RMSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_val_RMSE\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gianm\\Documents\\Uni\\Big Data\\F422\\project\\pose-estimation-from-emg-signal-team-1\\config\\validation.py:134\u001b[0m, in \u001b[0;36mcross_validate_pipeline\u001b[1;34m(pipeline, X_folds, Y_folds, metric_fns, n_folds, verbose)\u001b[0m\n\u001b[0;32m    131\u001b[0m Y_val \u001b[38;5;241m=\u001b[39m Y_folds[val_idx]\n\u001b[0;32m    133\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train)\n\u001b[1;32m--> 134\u001b[0m Y_train_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    135\u001b[0m Y_val_pred \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[0;32m    137\u001b[0m results[fold] \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\gianm\\Documents\\Uni\\Big Data\\F422\\project\\pose-estimation-from-emg-signal-team-1\\config\\regressors.py:37\u001b[0m, in \u001b[0;36mVotingRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     33\u001b[0m X \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(X)\n\u001b[0;32m     34\u001b[0m predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m     35\u001b[0m     [estimator\u001b[38;5;241m.\u001b[39mpredict(X) \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators]\n\u001b[0;32m     36\u001b[0m )\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gianm\\miniforge3\\envs\\test\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:556\u001b[0m, in \u001b[0;36maverage\u001b[1;34m(a, axis, weights, returned, keepdims)\u001b[0m\n\u001b[0;32m    554\u001b[0m     scl \u001b[38;5;241m=\u001b[39m avg_as_array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype(a\u001b[38;5;241m.\u001b[39msize\u001b[38;5;241m/\u001b[39mavg_as_array\u001b[38;5;241m.\u001b[39msize)\n\u001b[0;32m    555\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 556\u001b[0m     wgt \u001b[38;5;241m=\u001b[39m \u001b[43m_weights_are_valid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    558\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(a\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, (np\u001b[38;5;241m.\u001b[39minteger, np\u001b[38;5;241m.\u001b[39mbool)):\n\u001b[0;32m    559\u001b[0m         result_dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mresult_type(a\u001b[38;5;241m.\u001b[39mdtype, wgt\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gianm\\miniforge3\\envs\\test\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:399\u001b[0m, in \u001b[0;36m_weights_are_valid\u001b[1;34m(weights, a, axis)\u001b[0m\n\u001b[0;32m    395\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    396\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAxis must be specified when shapes of a and weights \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    397\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiffer.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wgt\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(a\u001b[38;5;241m.\u001b[39mshape[ax] \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m axis):\n\u001b[1;32m--> 399\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    400\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of weights must be consistent with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape of a along specified axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    403\u001b[0m \u001b[38;5;66;03m# setup wgt to broadcast along axis\u001b[39;00m\n\u001b[0;32m    404\u001b[0m wgt \u001b[38;5;241m=\u001b[39m wgt\u001b[38;5;241m.\u001b[39mtranspose(np\u001b[38;5;241m.\u001b[39margsort(axis))\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of weights must be consistent with shape of a along specified axis."
     ]
    }
   ],
   "source": [
    "# Define all your models (trained or pipelines)\n",
    "estimators = [\n",
    "    baseline_guided_kr,\n",
    "    baseline_guided_knn,\n",
    "    baseline_guided_rf,\n",
    "    riem1,\n",
    "    riem2,\n",
    "    riem3\n",
    "]\n",
    "\n",
    "# Define weight combinations manually (they must sum to 1)\n",
    "weight_sets = [\n",
    "    [1/6] * 6,  # uniform\n",
    "    [0.2, 0.2, 0.2, 0.2, 0.1, 0.1],\n",
    "    [0.1, 0.1, 0.4, 0.1, 0.15, 0.15],\n",
    "    [0.25, 0.25, 0.25, 0.0, 0.15, 0.10],\n",
    "    [0.4, 0.0, 0.0, 0.2, 0.2, 0.2],\n",
    "    [0.3, 0.3, 0.0, 0.1, 0.2, 0.1],\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.2, 0.2],\n",
    "    [0.15, 0.15, 0.15, 0.15, 0.2, 0.2],\n",
    "    [0.1, 0.1, 0.1, 0.2, 0.3, 0.2],\n",
    "    [0.2, 0.0, 0.3, 0.0, 0.3, 0.2],\n",
    "    [0.5, 0.2, 0.0, 0.0, 0.2, 0.1],\n",
    "    [0.6, 0.0, 0.0, 0.0, 0.2, 0.2],\n",
    "    [0.4, 0.3, 0.0, 0.1, 0.1, 0.1],\n",
    "    [0.3, 0.0, 0.1, 0.1, 0.3, 0.2],\n",
    "    [0.1, 0.1, 0.2, 0.2, 0.2, 0.2],\n",
    "    [0.0, 0.3, 0.3, 0.2, 0.1, 0.1],\n",
    "    [0.0, 0.0, 0.4, 0.2, 0.2, 0.2],\n",
    "    [0.0, 0.0, 0.0, 0.5, 0.3, 0.2],\n",
    "    [0.2, 0.2, 0.0, 0.0, 0.3, 0.3],\n",
    "    [0.1, 0.1, 0.1, 0.1, 0.3, 0.3]\n",
    "]\n",
    "\n",
    "# Track results\n",
    "results = []\n",
    "\n",
    "# Loop through each weight set and evaluate with cross-validation\n",
    "for weights in weight_sets:\n",
    "    ensemble = VotingRegressor(estimators=estimators, weights=weights)\n",
    "    \n",
    "    cv_scores = cross_validate_pipeline(\n",
    "        ensemble, X_guided_windows, Y_guided_labels, metric_fns, n_folds=5, verbose=0\n",
    "    )\n",
    "    results.append((weights, cv_scores['avg_val_RMSE']))\n",
    "    print(f\"Weights: {weights} → avg_val_RMSE: {cv_scores['avg_val_RMSE']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20e448b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Scores across folds:\n",
      "RMSE: train=1.8400, val=4.2512\n",
      "NMSE: train=0.0167, val=0.0906\n"
     ]
    }
   ],
   "source": [
    "ensemble = VotingRegressor(estimators=estimators, weights=[0.0, 0.3, 0.3, 0.2, 0.1, 0.1])\n",
    "results_guided = cross_validate_pipeline(ensemble, X_guided_windows, Y_guided_labels, metric_fns, n_folds=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebba378b",
   "metadata": {},
   "source": [
    "#### RMSE freemoves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21b09bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all your models (trained or pipelines)\n",
    "estimators = [\n",
    "    baseline_guided_kr,\n",
    "    baseline_guided_knn,\n",
    "    baseline_guided_rf,\n",
    "    riem1,\n",
    "    riem2,\n",
    "    riem3\n",
    "]\n",
    "\n",
    "# Define weight combinations manually (they must sum to 1)\n",
    "weight_sets = [\n",
    "    [1/6] * 6,  # uniform\n",
    "    [0.2, 0.2, 0.2, 0.2, 0.1, 0.1],\n",
    "    [0.1, 0.1, 0.4, 0.1, 0.15, 0.15],\n",
    "    [0.25, 0.25, 0.25, 0.0, 0.15, 0.10],\n",
    "    [0.4, 0.0, 0.0, 0.2, 0.2, 0.2],\n",
    "    [0.3, 0.3, 0.0, 0.1, 0.2, 0.1],\n",
    "    [0.2, 0.2, 0.1, 0.1, 0.2, 0.2],\n",
    "    [0.15, 0.15, 0.15, 0.15, 0.2, 0.2],\n",
    "    [0.1, 0.1, 0.1, 0.2, 0.3, 0.2],\n",
    "    [0.2, 0.0, 0.0, 0.3, 0.3, 0.2],\n",
    "    [0.5, 0.2, 0.0, 0.0, 0.2, 0.1],\n",
    "    [0.6, 0.0, 0.0, 0.0, 0.2, 0.2],\n",
    "    [0.4, 0.3, 0.0, 0.1, 0.1, 0.1],\n",
    "    [0.3, 0.0, 0.1, 0.1, 0.3, 0.2],\n",
    "    [0.1, 0.1, 0.2, 0.2, 0.2, 0.2],\n",
    "    [0.0, 0.3, 0.3, 0.2, 0.1, 0.1],\n",
    "    [0.0, 0.0, 0.4, 0.2, 0.2, 0.2],\n",
    "    [0.0, 0.0, 0.0, 0.5, 0.3, 0.2],\n",
    "    [0.2, 0.2, 0.0, 0.0, 0.3, 0.3],\n",
    "    [0.1, 0.1, 0.1, 0.1, 0.3, 0.3]\n",
    "]\n",
    "\n",
    "# Track results\n",
    "results = []\n",
    "\n",
    "# Loop through each weight set and evaluate with cross-validation\n",
    "for weights in weight_sets:\n",
    "    ensemble = VotingRegressor(estimators=estimators, weights=weights)\n",
    "    \n",
    "    cv_scores = cross_validate_pipeline(\n",
    "        ensemble, X_freemoves_windows, Y_freemoves_labels, metric_fns, n_folds=5, verbose=0\n",
    "    )\n",
    "    results.append((weights, cv_scores['avg_val_RMSE']))\n",
    "    print(f\"Weights: {weights} → avg_val_RMSE: {cv_scores['avg_val_RMSE']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ef94c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_fns = {'RMSE': RMSE, 'NMSE': NMSE}\n",
    "models = {\n",
    "    'Combined features + Kernel Ridge': baseline_guided_kr,\n",
    "    'Combined features + KNN': baseline_guided_knn,\n",
    "    'Combined features + RF': baseline_guided_rf,\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    results = cross_validate_pipeline(\n",
    "        model, \n",
    "        X_freemoves_windows, \n",
    "        Y_freemoves_labels, \n",
    "        metric_fns=metric_fns,\n",
    "        n_folds=5,\n",
    "        verbose=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae8f87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "base_models = [\n",
    "        baseline_guided_kr,\n",
    "        # baseline_guided_knn,\n",
    "        # baseline_guided_rf,\n",
    "        timedomain_xgboost,\n",
    "        # riem1,\n",
    "        # riem2,\n",
    "        # riem3,\n",
    "        riem4\n",
    "    ]\n",
    "\n",
    "meta_models = {\n",
    "    'Linear': LinearRegression(),\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': MultiOutputRegressor(Lasso()),\n",
    "    # 'SVR': MultiOutputRegressor(SVR()),\n",
    "    # 'MLP': MultiOutputRegressor(MLPRegressor(max_iter=500)),\n",
    "    # 'RF': RandomForestRegressor(n_estimators=50),\n",
    "    # 'XGB': XGBRegressor(objective='reg:squarederror')\n",
    "}\n",
    "\n",
    "for name, meta in meta_models.items():\n",
    "    model = StackingRegressor(estimators=base_models, end_estimator=meta)\n",
    "    results = cross_validate_pipeline(model, X_freemoves_windows, Y_freemoves_labels, metric_fns, n_folds=5, verbose=0)\n",
    "    print(f\"{name} meta: avg_val_RMSE = {results['avg_val_RMSE']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6021fae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Scores across folds:\n",
      "RMSE: train=3.9533, val=10.1630\n",
      "NMSE: train=0.0987, val=0.7275\n"
     ]
    }
   ],
   "source": [
    "ensemble = VotingRegressor(estimators=estimators, weights=[0.2, 0.2, 0.2, 0.2, 0.1, 0.1])\n",
    "results_freemoves = cross_validate_pipeline(ensemble, X_freemoves_windows, Y_freemoves_labels, metric_fns, n_folds=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f68ce3c",
   "metadata": {},
   "source": [
    "#### RMSE total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a62f06fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(7.789721324122596)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_combined = \\\n",
    "    ((results_guided['avg_val_RMSE']**2 * X_guided.shape[0] + \\\n",
    "    results_freemoves['avg_val_RMSE']**2 * X_freemoves.shape[0])/(X_guided.shape[0]+X_freemoves.shape[0]))**0.5\n",
    "\n",
    "results_combined # I think that this should be the result that is most correlated to the score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba40ba5",
   "metadata": {},
   "source": [
    "# Submission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f431d83a",
   "metadata": {},
   "source": [
    "### Guided training and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4346b0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'guided'\n",
    "\n",
    "# training\n",
    "X = np.load(PATH + f'{DATASET}/{DATASET}_dataset_X.npy')\n",
    "Y = np.load(PATH + f'{DATASET}/{DATASET}_dataset_Y.npy')\n",
    "\n",
    "tw_extractor = TimeWindowTransformer(size = 500, step = 50)\n",
    "label_extractor = LabelWindowExtractor(size = 500, step = 50)\n",
    "\n",
    "X_windows = tw_extractor.transform(X)\n",
    "Y_labels = label_extractor.transform(Y)\n",
    "\n",
    "X_train = X_windows.reshape(-1, *X_windows.shape[2:])\n",
    "Y_train = Y_labels.reshape(-1, *Y_labels.shape[2:])\n",
    "\n",
    "model_guided = VotingRegressor(estimators=estimators)\n",
    "\n",
    "model_guided.fit(X_train, Y_train)\n",
    "\n",
    "# predicting\n",
    "X_test = np.load(PATH + f'{DATASET}/{DATASET}_testset_X.npy')\n",
    "X_test = X_test.reshape(-1, *X_windows.shape[2:])\n",
    "\n",
    "Y_guided_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b298626a",
   "metadata": {},
   "source": [
    "### Freemoves training and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a73f541",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'freemoves'\n",
    "\n",
    "# training\n",
    "X = np.load(PATH + f'{DATASET}/{DATASET}_dataset_X.npy')\n",
    "Y = np.load(PATH + f'{DATASET}/{DATASET}_dataset_Y.npy')\n",
    "\n",
    "tw_extractor = TimeWindowTransformer(size = 500, step = 50)\n",
    "label_extractor = LabelWindowExtractor(size = 500, step = 50)\n",
    "\n",
    "X_windows = tw_extractor.transform(X)\n",
    "Y_labels = label_extractor.transform(Y)\n",
    "\n",
    "X_train = X_windows.reshape(-1, *X_windows.shape[2:])\n",
    "Y_train = Y_labels.reshape(-1, *Y_labels.shape[2:])\n",
    "\n",
    "model_freemoves = VotingRegressor(estimators=estimators, weights=[0.2, 0.2, 0.2, 0.2, 0.1, 0.1])\n",
    "\n",
    "model_freemoves.fit(X_train, Y_train)\n",
    "\n",
    "# predicting\n",
    "X_test = np.load(PATH + f'{DATASET}/{DATASET}_testset_X.npy')\n",
    "X_test = X_test.reshape(-1, *X_windows.shape[2:])\n",
    "\n",
    "Y_freemoves_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64d74dd",
   "metadata": {},
   "source": [
    "### CSV generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9222528f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fname = 'voting_step_50.csv'\n",
    "\n",
    "Y_pred = np.vstack([Y_guided_pred, Y_freemoves_pred])\n",
    "Y_pred_df = pd.DataFrame(Y_pred)\n",
    "Y_pred_df.to_csv(fname, index=False, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

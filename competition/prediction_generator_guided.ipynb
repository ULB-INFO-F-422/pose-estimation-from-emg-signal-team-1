{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5994871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ee26eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from config.regressors import VotingRegressor, StackingRegressor, NNRegressor\n",
    "\n",
    "from config.models import ConvNN\n",
    "\n",
    "from config.loss_functions import RMSELoss\n",
    "\n",
    "import pyriemann\n",
    "import pyriemann.regression\n",
    "\n",
    "from config.transformers import TimeDomainTransformer, TimeWindowTransformer, LabelWindowExtractor\n",
    "from config.validation import RMSE, NMSE, cross_validate_pipeline, cross_validate_NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ea8cb9",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455d5401",
   "metadata": {},
   "source": [
    "### Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c52f725c",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_guided_kr = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', TimeDomainTransformer(sigma_mpr=0.3)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', KernelRidge(\n",
    "            alpha = 0.01,\n",
    "            gamma = 0.01,\n",
    "            kernel='laplacian'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "baseline_guided_knn = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', TimeDomainTransformer(sigma_mpr=0.3)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', KNeighborsRegressor(\n",
    "            n_neighbors = 5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "baseline_guided_rf = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', TimeDomainTransformer(sigma_mpr=0.3)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', RandomForestRegressor(\n",
    "            n_estimators = 50,\n",
    "            max_depth = 10))\n",
    "    ]\n",
    ")\n",
    "\n",
    "timedomain_xgboost = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', TimeDomainTransformer(sigma_mpr=0.3)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', XGBRegressor(\n",
    "            n_estimators = 100,\n",
    "            max_depth = 5,\n",
    "            learning_rate = 0.1,\n",
    "            objective='reg:squarederror',\n",
    "            n_jobs=-1,\n",
    "            verbosity=1\n",
    "        ))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0785ada4",
   "metadata": {},
   "source": [
    "### Riemannian models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c84f91d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riemannian geometry of covariance matrices\n",
    "riem1 = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', pyriemann.estimation.Covariances()),\n",
    "        ('transformation', pyriemann.tangentspace.TangentSpace(\n",
    "            metric = 'riemann',\n",
    "            tsupdate = True)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', KernelRidge(\n",
    "            alpha = 0.01,\n",
    "            gamma = 0.01,\n",
    "            kernel='laplacian'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "riem2 = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', pyriemann.estimation.Covariances()),\n",
    "        ('transformation', pyriemann.tangentspace.TangentSpace(\n",
    "            metric = 'riemann',\n",
    "            tsupdate = True)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', KNeighborsRegressor(\n",
    "            n_neighbors = 5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "riem3 = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', pyriemann.estimation.Covariances()),\n",
    "        ('transformation', pyriemann.tangentspace.TangentSpace(\n",
    "            metric = 'riemann',\n",
    "            tsupdate = True)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', RandomForestRegressor(\n",
    "            n_estimators = 50,\n",
    "            max_depth = 10))\n",
    "    ]\n",
    ")\n",
    "\n",
    "riem4 = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', pyriemann.estimation.Covariances()),\n",
    "        ('transformation', pyriemann.tangentspace.TangentSpace(\n",
    "            metric = 'riemann',\n",
    "            tsupdate = True)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', XGBRegressor(\n",
    "            n_estimators = 100,\n",
    "            max_depth = 5,\n",
    "            learning_rate = 0.1,\n",
    "            objective='reg:squarederror',\n",
    "            n_jobs=-1,\n",
    "            verbosity=1\n",
    "        ))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed2284",
   "metadata": {},
   "source": [
    "### Ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6488776",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_estimator = VotingRegressor(\n",
    "    estimators = [\n",
    "        baseline_guided_kr,\n",
    "        baseline_guided_knn,\n",
    "        baseline_guided_rf,\n",
    "        riem1,\n",
    "        riem2,\n",
    "        riem3\n",
    "    ]\n",
    ")\n",
    "\n",
    "stacking_estimator = StackingRegressor(\n",
    "    estimators = [\n",
    "        baseline_guided_kr,\n",
    "        baseline_guided_knn,\n",
    "        baseline_guided_rf,\n",
    "        riem1,\n",
    "        riem2,\n",
    "        riem3\n",
    "    ],\n",
    "    end_estimator = RandomForestRegressor(\n",
    "        n_estimators = 50,\n",
    "        max_depth = 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae29bf95",
   "metadata": {},
   "source": [
    "# Final generalization evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d464e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = f'/Users/marco/PROJECTS/data/'\n",
    "# PATH = r'C:\\Users\\gianm\\Documents\\Uni\\Big Data\\F422\\project\\data\\\\'\n",
    "\n",
    "# ciao\n",
    "model = StackingRegressor(\n",
    "    estimators = [\n",
    "        baseline_guided_kr,\n",
    "        # baseline_guided_knn,\n",
    "        baseline_guided_rf,\n",
    "        # riem1,\n",
    "        # riem2,\n",
    "        riem3\n",
    "    ],\n",
    "    end_estimator = RandomForestRegressor(\n",
    "        n_estimators = 50,\n",
    "        max_depth = 10)\n",
    ")\n",
    "\n",
    "model_name = 'stacking_kr_rf_riem3'\n",
    "\n",
    "step = 250 # step used for testing\n",
    "\n",
    "metric_fns = {'RMSE': RMSE, 'NMSE': NMSE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a016181",
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_extractor = TimeWindowTransformer(size = 500, step = step)\n",
    "label_extractor = LabelWindowExtractor(size = 500, step = step)\n",
    "\n",
    "# guided\n",
    "DATASET = 'guided'\n",
    "\n",
    "X = np.load(PATH + f'{DATASET}/{DATASET}_dataset_X.npy')\n",
    "Y = np.load(PATH + f'{DATASET}/{DATASET}_dataset_Y.npy')\n",
    "X_windows = tw_extractor.transform(X)\n",
    "Y_labels = label_extractor.transform(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb5119d",
   "metadata": {},
   "source": [
    "#### 5-fold cross-validation freemoves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20e448b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "RMSE: train=0.7502, val=5.4499\n",
      "NMSE: train=0.0027, val=0.1532\n",
      "\n",
      "Fold 2\n",
      "RMSE: train=0.7367, val=4.2818\n",
      "NMSE: train=0.0027, val=0.0932\n",
      "\n",
      "Fold 3\n",
      "RMSE: train=0.7129, val=4.5268\n",
      "NMSE: train=0.0025, val=0.0963\n",
      "\n",
      "Fold 4\n",
      "RMSE: train=0.7206, val=3.5814\n",
      "NMSE: train=0.0025, val=0.0650\n",
      "\n",
      "Fold 5\n",
      "RMSE: train=0.7262, val=4.3402\n",
      "NMSE: train=0.0026, val=0.0896\n",
      "\n",
      "Average Scores across folds:\n",
      "RMSE: train=0.7293, val=4.4360\n",
      "NMSE: train=0.0026, val=0.0994\n"
     ]
    }
   ],
   "source": [
    "results = cross_validate_pipeline(model, X_windows, Y_labels, metric_fns, n_folds=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fbca538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4-44'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_rmse = str(np.round(results['avg_val_RMSE'], 2)).replace('.', '-')\n",
    "\n",
    "expected_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba40ba5",
   "metadata": {},
   "source": [
    "# Prediction generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4346b0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_prediction = 50 # step for prediction\n",
    "\n",
    "# preparing the training data\n",
    "tw_extractor = TimeWindowTransformer(size = 500, step = step_prediction)\n",
    "label_extractor = LabelWindowExtractor(size = 500, step = step_prediction)\n",
    "\n",
    "DATASET = 'guided'\n",
    "\n",
    "X = np.load(PATH + f'{DATASET}/{DATASET}_dataset_X.npy')\n",
    "Y = np.load(PATH + f'{DATASET}/{DATASET}_dataset_Y.npy')\n",
    "X_windows = tw_extractor.transform(X)\n",
    "Y_labels = label_extractor.transform(Y)\n",
    "\n",
    "# stacking the sessions \n",
    "X_train = X_windows.reshape(-1, *X_windows.shape[2:])\n",
    "Y_train = Y_labels.reshape(-1, *Y_labels.shape[2:])\n",
    "\n",
    "# training\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# predicting\n",
    "X_test = np.load(PATH + f'{DATASET}/{DATASET}_testset_X.npy')\n",
    "X_test = X_test.reshape(-1, *X_windows.shape[2:])\n",
    "Y_pred = model.predict(X_test)\n",
    "\n",
    "# saving\n",
    "FOLDER_PATH = f'{DATASET}/'\n",
    "file_name = FOLDER_PATH + model_name + '_steps_' + str(step_prediction) + '_rmse_' + expected_rmse\n",
    "\n",
    "np.save(file_name, Y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bgda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

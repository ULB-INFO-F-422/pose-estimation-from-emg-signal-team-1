{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b92cf27c",
   "metadata": {},
   "source": [
    "# Statistical foundation of machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e0a179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from prep import TimeWindowTransformer, LabelWindowExtractor, TimeDomainTransformer\n",
    "\n",
    "# adjust import if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d401a7",
   "metadata": {},
   "source": [
    "## Loading raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e218cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading raw data\n",
    "PATH = f'/Users/marco/PROJECTS/data/'\n",
    "# PATH = r'C:\\Users\\gianm\\Documents\\Uni\\Big Data\\F422\\project\\data\\\\'\n",
    "DATASET = 'guided' # change this to guided/freemoves if needed\n",
    "\n",
    "X = np.load(PATH + f'{DATASET}/{DATASET}_dataset_X.npy')\n",
    "Y = np.load(PATH + f'{DATASET}/{DATASET}_dataset_Y.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3adc425",
   "metadata": {},
   "source": [
    "## (Optional) Signal filtering\n",
    "\n",
    "if you plan to filter your sEMG signals, it is recommended to perform\n",
    "this preprocessing step directly on the continuous raw data prior to window extraction or feature\n",
    "computation. Note that this step is completely optional but may improve your results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093990ea",
   "metadata": {},
   "source": [
    "## (0.5 point) Dataset preparation and augmentation through overlapping windows\n",
    "\n",
    "You should first segment your sEMG signals into smaller windows of fixed size k = 500. These windows should be created with a chosen degree of overlap, which you can adjust based on the computational and memory resources available to you. Keep in mind that a larger overlap results in a greater number of samples and thus a larger dataset to train your models but to the cost of increasing computational demands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a311f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "size = 500\n",
    "step = 250\n",
    "\n",
    "# Initialize transformers\n",
    "tw_transformer = TimeWindowTransformer(size=size, step=step)\n",
    "label_extractor = LabelWindowExtractor(size=size, step=step)\n",
    "\n",
    "# Apply transformations\n",
    "X_windows = tw_transformer.transform(X)     # shape: (5, n_windows, 8, 500)\n",
    "Y_labels = label_extractor.transform(Y)     # shape: (5, n_windows, 51)\n",
    "\n",
    "# Inspect shapes\n",
    "print(\"X_windows shape:\", X_windows.shape)\n",
    "print(\"Y_labels shape:\", Y_labels.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6921d1",
   "metadata": {},
   "source": [
    "## (1 point) Cross-validation strategy\n",
    "\n",
    "Determine and implement an adequate cross-validation strategy to validate your regression models, specifying how you organized your data partitions for training and validation. Provide a detailed justification showing that your validation sets remain completely independent from the training set. Include reasoning or evidence demonstrating explicitly that your chosen partitioning strategy prevents data leakage or bias, ensuring the reliability and generalizability of your model performance estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d5c4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = X_windows[:4]\n",
    "Y_train_val = Y_labels[:4]\n",
    "X_test = X_windows[4]\n",
    "Y_test = Y_labels[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b261336d",
   "metadata": {},
   "source": [
    "## (3 points) Baseline approach\n",
    "\n",
    "Create a custom class inheriting from scikit-learnâ€™s `BaseEstimator`\n",
    "and `TransformerMixin` that implements the extraction of common time-domain features described\n",
    "in section 3.1. Note that the features described in Section 3.1 represent the minimal required set. We\n",
    "encourage you to include additional features or preprocessing steps if you would like to further improve your model performances. Select at least two different regression models, compare their cross-validated performance, and evaluate their feature importances. For both models, perform feature selection to determine the optimal subset of features minimizing the Root Mean Squared Error (RMSE).\n",
    "Clearly document this process in your notebook, discussing the outcomes in detail. Finally, create a\n",
    "scikit-learn `Pipeline` that integrates your custom feature extraction class, the optimal feature selection step, and the best-performing regression model identified from your cross-validation results.\n",
    "Using visualizations and tables to illustrate your findings, and employing formulas or pseudo-code\n",
    "to explain the feature selection procedure, is strongly encouraged. Note that one-third of the score\n",
    "will depend on the quality and clarity of your documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f50af99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from validation import *\n",
    "\n",
    "import pyriemann\n",
    "import pyriemann.regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46283caf",
   "metadata": {},
   "source": [
    "### Time domain pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db28905f",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_est0 = Pipeline(\n",
    "    [\n",
    "        ('time_domain_features', TimeDomainTransformer(0.3)),\n",
    "        ('regressor', Lasso())\n",
    "    ]\n",
    ")\n",
    "\n",
    "time_est1 = Pipeline(\n",
    "    [\n",
    "        ('time_domain_features', TimeDomainTransformer()),\n",
    "        ('kernel_ridge', KernelRidge())\n",
    "    ]\n",
    ")\n",
    "\n",
    "time_est2 = Pipeline(\n",
    "    [\n",
    "        ('time_domain_features', TimeDomainTransformer()),\n",
    "        ('multioutput_svr', MultiOutputRegressor(SVR()))\n",
    "    ]\n",
    ")\n",
    "\n",
    "time_est3 = Pipeline(\n",
    "    [\n",
    "        ('time_domain_features', TimeDomainTransformer()),\n",
    "        ('decision_tree', DecisionTreeRegressor())\n",
    "    ]\n",
    ")\n",
    "\n",
    "time_est4 = Pipeline(\n",
    "    [\n",
    "        ('time_domain_features', TimeDomainTransformer()),\n",
    "        ('extra_tree', ExtraTreeRegressor())\n",
    "    ]\n",
    ")\n",
    "\n",
    "time_est5 = Pipeline(\n",
    "    [\n",
    "        ('time_domain_features', TimeDomainTransformer()),\n",
    "        ('random_forest', RandomForestRegressor(\n",
    "            n_estimators = 30\n",
    "        ))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a05614f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Evaluation ---\n",
    "# X_train_val and Y_train_val must be loaded before calling this\n",
    "metric_fns = {'RMSE': RMSE, 'NMSE': NMSE}\n",
    "\n",
    "all_results = {}\n",
    "for i, pipeline in enumerate([time_est0, time_est1, time_est2, time_est3, time_est4, time_est5]):\n",
    "    print(f\"\\n--- Evaluating time_est{i} ---\")\n",
    "    result = cross_validate_pipeline(pipeline, X_train_val, Y_train_val, metric_fns)\n",
    "    all_results[f'time_est{i}'] = result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fb85ea",
   "metadata": {},
   "source": [
    "### Riemannian geometry pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eb30e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ----- Riemannian geometry of covariance matrices ----- #\n",
    "geom_est0 = Pipeline(\n",
    "    [\n",
    "        ('cov_matrices', pyriemann.estimation.Covariances()),\n",
    "        ('svr', MultiOutputRegressor(pyriemann.regression.SVR()))\n",
    "    ]\n",
    ")\n",
    "\n",
    "geom_est1 = Pipeline(\n",
    "    [\n",
    "        ('cov_matrices', pyriemann.estimation.Covariances()),\n",
    "        ('projection', pyriemann.tangentspace.TangentSpace(\n",
    "            metric = 'riemann',\n",
    "            tsupdate = True)),\n",
    "        ('kernel_ridge', KernelRidge(\n",
    "            kernel='laplacian'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "geom_est2 = Pipeline(\n",
    "    [\n",
    "        ('cov_matrices', pyriemann.estimation.Covariances()),\n",
    "        ('projection', pyriemann.tangentspace.TangentSpace(\n",
    "            metric = 'riemann',\n",
    "            tsupdate = True)),\n",
    "        ('regressor', RandomForestRegressor())\n",
    "    ]\n",
    ")\n",
    "\n",
    "geom_est3 = Pipeline(\n",
    "    [\n",
    "        ('cov_matrices', pyriemann.estimation.Covariances()),\n",
    "        ('projection', pyriemann.tangentspace.TangentSpace(\n",
    "            metric = 'riemann',\n",
    "            tsupdate = True)),\n",
    "        ('regressor', Lasso())\n",
    "    ]\n",
    ")\n",
    "\n",
    "geom_est4 = Pipeline(\n",
    "    [\n",
    "        ('cov_matrices', pyriemann.estimation.Covariances()),\n",
    "        ('projection', pyriemann.tangentspace.TangentSpace(\n",
    "            metric = 'riemann',\n",
    "            tsupdate = True)),\n",
    "        ('regressor', MultiOutputRegressor(GradientBoostingRegressor()))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a29de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Kernels for ridge:')\n",
    "display({'additive_chi2', 'polynomial', 'laplacian', 'poly', 'sigmoid', 'precomputed', 'cosine', 'rbf', 'linear', 'chi2'})\n",
    "print('Kernels for SVR:')\n",
    "display({'linear', 'poly', 'rbf', 'sigmoid'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f234b6e9",
   "metadata": {},
   "source": [
    "### Ensemble regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31beb0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ensemble import VotingRegressor\n",
    "\n",
    "ens_est0 = VotingRegressor(\n",
    "    estimators = [time_est5, geom_est1, geom_est4]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe32c4c8",
   "metadata": {},
   "source": [
    "### Estimator validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90acc713",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = geom_est1 # change this to validate another pipeline\n",
    "\n",
    "results = {}\n",
    "for fold in range(4):\n",
    "    train_idx = [0,1,2,3]\n",
    "    train_idx.remove(fold)\n",
    "    val_idx = fold\n",
    "\n",
    "    X_train = X_train_val[train_idx].reshape(-1, *X_train_val.shape[2:])\n",
    "    Y_train = Y_train_val[train_idx].reshape(-1, *Y_train_val.shape[2:])\n",
    "    X_val = X_train_val[val_idx]\n",
    "    Y_val = Y_train_val[val_idx]\n",
    "    \n",
    "    pipeline.fit(X_train, Y_train)\n",
    "    Y_train_pred = pipeline.predict(X_train)\n",
    "    Y_val_pred = pipeline.predict(X_val)\n",
    "    print(f\"Fold {fold+1}\\n.\\\n",
    "          train RMSE:\\t{RMSE(Y_train_pred, Y_train):.4f}\\ttrain NMSE:\\t{NMSE(Y_train_pred, Y_train):.4f}\\n.\\\n",
    "            val RMSE:\\t{RMSE(Y_val_pred, Y_val):.4f}\\tval NMSE:\\t{NMSE(Y_val_pred, Y_val):.4f}\")\n",
    "    \n",
    "    results[fold] = {\n",
    "        'train_RMSE': RMSE(Y_train_pred, Y_train),\n",
    "        'train_NMSE': NMSE(Y_train_pred, Y_train),\n",
    "        'val_RMSE': RMSE(Y_val_pred, Y_val),\n",
    "        'val_NMSE': NMSE(Y_val_pred, Y_val),\n",
    "    }\n",
    "\n",
    "mean_val_RMSE = np.mean([dic['val_RMSE'] for dic in results.values()])\n",
    "mean_val_NMSE = np.mean([dic['val_NMSE'] for dic in results.values()])\n",
    "print('Mean val RMSE:', mean_val_RMSE)\n",
    "print('Mean val NMSE:', mean_val_NMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111a49a0",
   "metadata": {},
   "source": [
    "### Visualizing predictions to unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3dc537",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val_flat = X_train_val.reshape(-1, *X_train_val.shape[2:])\n",
    "Y_train_val_flat = Y_train_val.reshape(-1, *Y_train_val.shape[2:])\n",
    "\n",
    "pipeline.fit(X_train_val_flat, Y_train_val_flat)\n",
    "Y_train_pred = pipeline.predict(X_train_val_flat)\n",
    "Y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(f\"train RMSE:\\t{RMSE(Y_train_pred, Y_train_val_flat):.4f}\\ttrain NMSE:\\t{NMSE(Y_train_pred, Y_train_val_flat):.4f}\\ntest RMSE:\\t{RMSE(Y_test_pred, Y_test):.4f}\\ttest NMSE:\\t{NMSE(Y_test_pred, Y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624edfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization_tools import scatter_3d_points\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib ipympl\n",
    "\n",
    "bone = 6\n",
    "Y_true_bone = Y_test[:,3*bone:3*(bone+1)]\n",
    "Y_pred_bone = Y_test_pred[:,3*bone:3*(bone+1)]\n",
    "\n",
    "print(f'RMSE for bone {bone}:', RMSE(Y_pred_bone, Y_true_bone))\n",
    "print(f'NMSE for bone {bone}:', NMSE(Y_pred_bone, Y_true_bone))\n",
    "\n",
    "ax = scatter_3d_points(Y_true_bone, color = 'b')\n",
    "scatter_3d_points(Y_pred_bone, color = 'r', ax = ax)\n",
    "# ax.set_xlim3d(-50, 50)\n",
    "# ax.set_ylim3d(-50, 50)\n",
    "# ax.set_zlim3d(-50, 50)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bgda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

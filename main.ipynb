{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b92cf27c",
   "metadata": {},
   "source": [
    "# **Statistical foundation of machine learning**\n",
    "\n",
    "General description of the problem here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe5438e",
   "metadata": {},
   "source": [
    "# Dataset preparation & cross-validation strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6005faa",
   "metadata": {},
   "source": [
    "We load and organize the raw data as follows:\n",
    "\n",
    "1. *Guided Dataset*:\n",
    "    - a numpy array `X_guided` of shape `(5, 8, 230000)`;\n",
    "    - a numpy array `Y_guided` of shape `(5, 51, 230000)`,\n",
    "\n",
    "2. *Freemoves Dataset*:\n",
    "    - a numpy array `X_freemoves` of shape `(5, 8, 270000)`;\n",
    "    - a numpy array `Y_freemoves` of shape `(5, 8, 270000)`.\n",
    "    \n",
    "The arrays `X_guided` and `X_freemoves` each consist of five sessions of eight raw EMG signals, with lengths of `230000` and `270000` samples, respectively. Their counterparts, `Y_guided` and `Y_freemoves`, hold the synchronized time‑series for 51 joint‑angle components (17 joints × 3 components) organized over the same five sessions. The data is sampled at 1024Hz, so 1024 samples correspond to one second of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6c68af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading raw data\n",
    "import numpy as np\n",
    "\n",
    "PATH = f'/Users/marco/PROJECTS/data/'\n",
    "# PATH = r'C:\\Users\\gianm\\Documents\\Uni\\Big Data\\F422\\project\\data\\\\'\n",
    "\n",
    "DATASET = 'guided'\n",
    "X_guided = np.load(PATH + f'{DATASET}/{DATASET}_dataset_X.npy')         # shape (5, 8, 230000)\n",
    "Y_guided = np.load(PATH + f'{DATASET}/{DATASET}_dataset_Y.npy')         # shape (5, 51, 230000)\n",
    "\n",
    "DATASET = 'freemoves'\n",
    "X_freemoves = np.load(PATH + f'{DATASET}/{DATASET}_dataset_X.npy')      # shape (5, 8, 270000)\n",
    "Y_freemoves = np.load(PATH + f'{DATASET}/{DATASET}_dataset_Y.npy')      # shape (5, 51, 270000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892e0e8a",
   "metadata": {},
   "source": [
    "The main objective of this project is to predict the joint angle data at time `t` in terms of a portion of the EMG signals ending at time `t`.\n",
    "\n",
    "To prepare our dataset for this regression tasks, we segment the EMG signals into overlapping windows of fixed size. This preprocessing step is crucial as it enables the learning models to capture localized temporal patterns in muscle activity and link them to corresponding hand pose estimations.\n",
    "\n",
    "We choose a **window size of 500 samples**, which corresponds to roughly **0.49 seconds** of EMG data, given the sampling rate of **1024 Hz**. This window size strikes a balance between capturing enough signal dynamics and ensuring real-time usability for prosthesis control.\n",
    "\n",
    "We implement a **50% overlap**, meaning each window starts 250 samples after the previous one. This overlap increases the number of training samples without excessively inflating computational costs. Larger overlaps (e.g., 75%) generate even more samples but demand significantly more memory and processing time, which may not scale efficiently depending on available resources.\n",
    "\n",
    "This approach is implemented using the custom transformer classes `TimeWindowTransformer` and `LabelWindowExtractor`, implemented and documented in the module `config.transformers`. To initialize instances of these classes, we need to pass two parameters:\n",
    "\n",
    "- `size`: the size of the time windows (in our case, typically `size=500`);\n",
    "\n",
    "- `step`: the step separating two consecutive time windows (in our case, at train/evaluation time we will use `step = 250`, but at prediction time we will use a smaller value to obtain more precise predictions).\n",
    "\n",
    "The most important method of these transformers is the `.transform()` method. For example:\n",
    "\n",
    "- For an instance `tw_transformer` of `TimeWindowTransformer`, the `.transform()` method takes in input a numpy array `X` of raw EMG signals (shape `(..., n_channels, n_times)`) and returns a numpy array `X_windows` of time windows (shape `(...,n_windows, n_channels, window_size)`);\n",
    "\n",
    "- For an instance `label_extractor` of `LabelWindowExtractor`, the `.transform()` method takes in input a numpy array `Y` of time-series of joint angle vectors (shape `(..., n_angles, n_times)`) and returns a numpy array `Y_labels` extracting the last joint angle vector for each time window (shape `(...,n_windows, n_angles)`).\n",
    "\n",
    "These transformers are easier to use than to describe! Below we have an explicit example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd02f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.transformers import TimeWindowTransformer, LabelWindowExtractor\n",
    "\n",
    "# define parameters\n",
    "size = 500\n",
    "step = 250\n",
    "\n",
    "# initialize transformers\n",
    "tw_transformer = TimeWindowTransformer(size=size, step=step)\n",
    "label_extractor = LabelWindowExtractor(size=size, step=step)\n",
    "\n",
    "# apply transformations\n",
    "X_guided_windows = tw_transformer.transform(X_guided)           # shape: (5, n_windows, 8, 500)\n",
    "Y_guided_labels = label_extractor.transform(Y_guided)           # shape: (5, n_windows, 51)\n",
    "\n",
    "X_freemoves_windows = tw_transformer.transform(X_freemoves)     # shape: (5, n_windows, 8, 500)\n",
    "Y_freemoves_labels = label_extractor.transform(Y_freemoves)     # shape: (5, n_windows, 51)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea00bf89",
   "metadata": {},
   "source": [
    "### Cross-validation strategy\n",
    "\n",
    "The regression problem can be formulated schematically as follows: given a time window `X` of EMG data (shape `(8, 500)`), we need to predict the vector of joint angles (shape `(51,)` ) corresponding to the hand configuration at the end of the time window.\n",
    "\n",
    "We can therefore consider each of the *guided* and *freemoves* datasets as a dataset of `N` labeled pairs `(X,y)`, where `X` is a EMG time window and `y` is its corresponding vector of joint angles. The data is organized across *five sessions*.\n",
    "\n",
    "It is **not appropriate** to naively stack these sessions together and then perform cross-validation on the stacked dataset, as this can lead to **leakage**. The problem is that some time windows overlap; with a naive cross-validation on the stacked dataset, we risk having pairs `(X,y)` in the validation set which overlap with pairs in the training set.\n",
    "\n",
    "To rigorously evaluate the performance and generalization capabilities of our regression models, we instead implement a **Leave-One-Session-Out cross-validation strategy** that ensures independence between training and validation data.\n",
    "\n",
    "The available data consists of 5 sessions. We use the first **4 sessions** (referred to as the `train_val` part of the data) for training and validation, and **reserve the 5th session** as completely unseen data (referred to as the `test` part of the data). This separation allows us to evaluate and tune our models on the `train_val` part of the data, and then finally evaluate the ability of our models to generalize by measuring their performance on the `test` session.\n",
    "\n",
    "We will train and validate our models on the `train_val` portion of the data by adopting a **Leave-One-Session-Out 4-fold cross-validation** strategy. Specifically, we will repeatedly train our model on three out of the four `train_val` sessions, and then validate the model on the remaining fourth `train_val` session, for each possible choice of the validation session. The performance is then evaluated in terms of two metrics:\n",
    "\n",
    "- the average of the *Root Mean Squared Errors* (**RMSE**) across folds;\n",
    "- the average of the *Normalized Mean Squared Errors* (**NMSE**) across folds.\n",
    "\n",
    "We will cross-validate our `sklearn`-compatible models by means of the custom `cross_validate_pipeline` function, implemented and documented in the module `config.validation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6bdf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate between train_val and test datasets\n",
    "X_guided_windows_train_val_folds = X_guided_windows[:4]         # shape (4, N, 8, 500)\n",
    "Y_guided_labels_train_val_folds = Y_guided_labels[:4]           # shape (4, N, 51)\n",
    "X_guided_windows_test = X_guided_windows[4]                     # shape (N, 8, 500)\n",
    "Y_guided_labels_test = Y_guided_labels[4]                       # shape (N, 51)\n",
    "\n",
    "X_freemoves_windows_train_val_folds = X_freemoves_windows[:4]   # shape (4, N, 8, 500)\n",
    "Y_freemoves_labels_train_val_folds = Y_freemoves_labels[:4]     # shape (4, N, 51)\n",
    "X_freemoves_windows_test = X_freemoves_windows[4]               # shape (N, 8, 500)\n",
    "Y_freemoves_labels_test = Y_freemoves_labels[4]                 # shape (N, 51)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0ad6af",
   "metadata": {},
   "source": [
    "# Baseline pipelines\n",
    "\n",
    "Create a custom class inheriting from scikit-learn’s `BaseEstimator`\n",
    "and `TransformerMixin` that implements the extraction of common time-domain features described\n",
    "in section 3.1. Note that the features described in Section 3.1 represent the minimal required set. We\n",
    "encourage you to include additional features or preprocessing steps if you would like to further improve your model performances. Select at least two different regression models, compare their cross-validated performance, and evaluate their feature importances. For both models, perform feature selection to determine the optimal subset of features minimizing the Root Mean Squared Error (RMSE).\n",
    "Clearly document this process in your notebook, discussing the outcomes in detail. Finally, create a\n",
    "scikit-learn `Pipeline` that integrates your custom feature extraction class, the optimal feature selection step, and the best-performing regression model identified from your cross-validation results.\n",
    "Using visualizations and tables to illustrate your findings, and employing formulas or pseudo-code\n",
    "to explain the feature selection procedure, is strongly encouraged. Note that one-third of the score\n",
    "will depend on the quality and clarity of your documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8791a5c5",
   "metadata": {},
   "source": [
    "### Time-domain features\n",
    "\n",
    "To establish a robust performance benchmark, we design a baseline approach that uses standard time-domain features extracted from the raw EMG signal windows. These features have been widely used in EMG-based classification and regression problems, due to their low computational cost and effectiveness in capturing muscle activity dynamics.\n",
    "\n",
    "In order to extract time-domain features, we implement a custom class `TimeDomainTransformer`, inheriting from `BaseEstimator` and `TransformerMixin`. This class is implemented and documented in `config.transformers`.\n",
    "\n",
    "An instance of `TimeDomainTransformer` has two main methods:\n",
    "\n",
    "- a `.fit(X, y)` method: this method does not really do anything, it simply returns the instance of the custom class; it is necessary for compatibility with sklearn's pipeline usage;\n",
    "\n",
    "- a `.transform(X)` method: this method takes in input a numpy array of EMG signals of shape `(...,n_channels, n_times)` (in our case, typically `n_channels = 8` and `n_times = 500`), and returns a numpy array of shape `(...,12)` containing 12 key time-domain features from each EMG signal, for a total of **96 features**.\n",
    "\n",
    "We implement the following 12 aggregate statistics:\n",
    "\n",
    "- **MAV** – Mean Absolute Value\n",
    "- **RMS** – Root Mean Square\n",
    "- **VAR** – Variance\n",
    "- **STD** – Standard Deviation\n",
    "- **ZC** – Zero Crossing Count\n",
    "- **MPR** – Myopulse Percentage Rate (using a tunable threshold `sigma_mpr`)\n",
    "- **MAA** – Maximum Absolute Amplitude\n",
    "- **WL** – Waveform Length\n",
    "- **SSC** – Slope Sign Changes\n",
    "- **WA** – Wilson Amplitude\n",
    "- **MFL** – Maximum Fractal Length\n",
    "- **KRT** – Kurtosis\n",
    "\n",
    "Below is a usage example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340bb4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.transformers import TimeDomainTransformer\n",
    "\n",
    "tw_transformer = TimeDomainTransformer() # initialize instance of the time-domain transformer\n",
    "\n",
    "array_of_EMG_signals = X_guided_windows_train_val_folds[0]                  # N time windows, shape (N, 8, 500)\n",
    "array_of_time_features = tw_transformer.transform(array_of_EMG_signals)     # N feature vectors, shape (N, 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403d4f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization via pandas\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "feature_names = ['MAV', 'RMS', 'VAR', 'STD', 'ZC', 'MPR', 'MAA', 'WL', 'SSC', 'WA', 'MFL', 'KRT']\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data = array_of_time_features,\n",
    "    columns = [feature + f'_{channel}' for channel, feature in itertools.product(np.arange(8), feature_names)]\n",
    "    )\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e436f77",
   "metadata": {},
   "source": [
    "### Baseline estimators\n",
    "\n",
    "We will now construct three sklearn-compatible pipelines, using different regression algorithms to predict joint angles from time-domain features extracted from EMG time windows. We will then evaluate the cross-validated performance of those pipelines. These will be our *baseline* results, on which we will compare more complex models. Later, we will improve the baseline results by:\n",
    "\n",
    "- adding more layers to the pipelines (eg. *filters* and *feature selection transformers*);\n",
    "- developing new pipelines based on different features extracted from EMG signals, such as *covariance matrices*;\n",
    "- developing *convolutional neural networks*, working directly on EMG time windows;\n",
    "- wrap the previously defined model together into *ensemble methods*.\n",
    "\n",
    "Each baseline pipeline follows the same general structure:\n",
    "\n",
    "1. **Feature Extraction**  \n",
    "   Extracts 12 time-domain features from each EMG channel, using the transformer `TimeDomainTransformer` described above.\n",
    "\n",
    "2. **Standardization**  \n",
    "   Normalizes the extracted features using the `sklearn` transformer `StandardScaler`, to ensure that each feature contributes equally to the regression model.\n",
    "\n",
    "3. **Regression Model**  \n",
    "   Each pipeline uses a different learning algorithm:\n",
    "   - **Kernel Ridge Regression**\n",
    "   - **K-Nearest Neighbors Regression**\n",
    "   - **Random Forest Regression**\n",
    "\n",
    "We chose these three regression models for two main reasons:\n",
    "* **Empirical reason:** We tested various regression models available in the sklearn library, and these three seemed to have a good performance compared to the others; for reasons of space, we did not include our numerous attempts in this notebook.\n",
    "\n",
    "* **Expected non-correlation:** Later in the notebook, we will combine our baseline estimators into *ensemble models*. It is well-known that ensemble models work well when the base learners are not very correlated to each other. The three regressors we chose are based on different regression methods:\n",
    "    - **Ridge Regression** is a *linear model*, adapted to our non-linear problem by means of the *kernel trick*;\n",
    "\n",
    "    - **KNN** is a *distance-based* model;\n",
    "\n",
    "    - **Random Forest** is a *tree-based* ensemble model.\n",
    "  \n",
    "  By choosing base learners which adopt different regression strategies, we hope to achieve significant improvement by employing ensemble strategies later.\n",
    "\n",
    "> **DISCLAIMER**\n",
    "\n",
    "All models and pipelines developed in this project adhere to the following input/output logic, to ensure compatibility with the dataset and evaluation routines:\n",
    "\n",
    "- `model.fit(X, y)`  \n",
    "  - **Input:**  \n",
    "    - `X`: numpy array of shape `(N, n_channels, n_times)` — N windows of raw EMG signals of length `n_times`, organized in `n_channels` channels (in our case, typically `n_channels = 8` and `n_times = 500`);\n",
    "    - `y`: numpy array of shape `(N, n_angles)` — corresponding N vectors of `n_angles` joint-angle labels (in our case, typically `n_angles = 51`).\n",
    "  - **Note:** This method fits the model in place; the return value is not used.\n",
    "\n",
    "- `model.predict(X)`  \n",
    "  - **Input:** `X`: numpy array of shape `(N, n_channels, n_times)`;\n",
    "  - **Output:** numpy array of shape `(N, n_angles)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5d1f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a440ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_kr = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', TimeDomainTransformer(sigma_mpr=0.3)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', KernelRidge(\n",
    "            alpha = 0.01,\n",
    "            gamma = 0.01,\n",
    "            kernel='laplacian'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "baseline_knn = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', TimeDomainTransformer(sigma_mpr=0.3)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', KNeighborsRegressor(\n",
    "            n_neighbors = 5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "baseline_rf = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', TimeDomainTransformer(sigma_mpr=0.3)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', RandomForestRegressor(\n",
    "            n_estimators = 50,\n",
    "            max_depth = 10))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441dbcc1",
   "metadata": {},
   "source": [
    "### Baseline evaluation via cross-validation\n",
    "\n",
    "To evaluate our baseline models, we apply the **4-fold cross-validation** strategy described previously. For each model, we report both:\n",
    "\n",
    "- average **Root Mean Squared Error (RMSE)** across folds;\n",
    "\n",
    "- average **Normalized Mean Squared Error (NMSE)** across folds.\n",
    "\n",
    "To compute these metrics, we use the functions `RMSE` and `NMSE` implemented and documented in the module `config.validation`.\n",
    "\n",
    "Before diving into the full cross-validation report, let's first provide a manual fit/predict example run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd535b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.validation import RMSE, NMSE\n",
    "\n",
    "# prepare training and validation data\n",
    "X_train = np.vstack(X_guided_windows_train_val_folds[:3])   # stacked first 3 sessions, shape (3*N, 8, 500)\n",
    "Y_train = np.vstack(Y_guided_labels_train_val_folds[:3])    # stacked first 3 sessions, shape (3*N, 51)\n",
    "\n",
    "X_val = X_guided_windows_train_val_folds[3]                 # validation session, shape (N, 8, 500)\n",
    "Y_val = Y_guided_labels_train_val_folds[3]                 # validation session, shape (N, 51)\n",
    "\n",
    "# choose an example model\n",
    "model = baseline_knn\n",
    "\n",
    "# fit the model\n",
    "model.fit(X_train, Y_train) # fits the model in-place\n",
    "\n",
    "# compute predictions\n",
    "Y_pred = model.predict(X_val) # shape (N, 51)\n",
    "\n",
    "# compute errors\n",
    "rmse_error = RMSE(Y_pred, Y_val)\n",
    "nmse_error = NMSE(Y_pred, Y_val)\n",
    "\n",
    "print(f'RMSE error: {rmse_error:.2f}')\n",
    "print(f'NMSE error: {nmse_error:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0b6383",
   "metadata": {},
   "source": [
    "We can now proceed with full-fledged cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e688c71",
   "metadata": {},
   "source": [
    "#### 4-fold Leave-One-Session-Out cross-validation of baseline models on *guided* dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5c60da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.validation import cross_validate_pipeline, RMSE, NMSE # custom cross-validation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8211a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"baseline_kr\" on the guided dataset:')\n",
    "results_guided_baseline_kr = cross_validate_pipeline(\n",
    "    pipeline = baseline_kr,\n",
    "    X_folds = X_guided_windows_train_val_folds,\n",
    "    Y_folds = Y_guided_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"baseline_knn\" on the guided dataset:')\n",
    "results_guided_baseline_knn = cross_validate_pipeline(\n",
    "    pipeline = baseline_knn,\n",
    "    X_folds = X_guided_windows_train_val_folds,\n",
    "    Y_folds = Y_guided_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"baseline_rf\" on the guided dataset:')\n",
    "results_guided_baseline_rf = cross_validate_pipeline(\n",
    "    pipeline = baseline_rf,\n",
    "    X_folds = X_guided_windows_train_val_folds,\n",
    "    Y_folds = Y_guided_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bc829a",
   "metadata": {},
   "source": [
    "#### 4-fold Leave-One-Session-Out cross-validation of baseline models on *freemoves* dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ef9025",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"baseline_kr\" on the freemoves dataset:')\n",
    "results_freemoves_baseline_kr = cross_validate_pipeline(\n",
    "    pipeline = baseline_kr,\n",
    "    X_folds = X_freemoves_windows_train_val_folds,\n",
    "    Y_folds = Y_freemoves_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"baseline_knn\" on the freemoves dataset:')\n",
    "results_freemoves_baseline_knn = cross_validate_pipeline(\n",
    "    pipeline = baseline_knn,\n",
    "    X_folds = X_freemoves_windows_train_val_folds,\n",
    "    Y_folds = Y_freemoves_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"baseline_rf\" on the freemoves dataset:')\n",
    "results_freemoves_baseline_rf = cross_validate_pipeline(\n",
    "    pipeline = baseline_rf,\n",
    "    X_folds = X_freemoves_windows_train_val_folds,\n",
    "    Y_folds = Y_freemoves_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29366070",
   "metadata": {},
   "source": [
    "# Features selection on baseline pipeline\n",
    "\n",
    "In order to perform feature selection to determine the optimal subset of features minimizing the Root Mean Squared Error (RMSE) for hand pose estimation, we implemented two approaches: **mRMR (Minimum Redundancy Maximum Relevance)** and **PCA**. Feature selection might help us to mitigate the curse of dimensionality, reducing the risk of overfitting our regression models, and identify the most informative features from the extracted time-domain characteristics of the EMG signals.\n",
    "\n",
    "## mRMR\n",
    "We want to start exploring the feature selection with the use of **Minimum Redundancy Maximum Relevance (mRMR)** strategy, based on a correlation-based approximation of mutual information. The core idea of mRMR is to select features that have high individual correlation with the target variables (maximum relevance) while having low correlation with each other (minimum redundancy). This helps in building a more robust and interpretable model.\n",
    "To estimate the relevance of each feature to the outputs (joint angles), we approximate **Mutual Information (MI)** using the correlation coefficient:\n",
    "\n",
    "$$\n",
    "\\text{MI}(x, y) \\approx -\\frac{1}{2} \\log(1 - \\rho^2)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\rho$ is the **Pearson correlation coefficient**\n",
    "- This approximation assumes **joint Gaussianity**\n",
    "\n",
    "Here's a sketch of the implementation:\n",
    "```python\n",
    "def mutual_info_corr(x, y):\n",
    "    \"\"\"\n",
    "    Approximates mutual information between x and y via Pearson correlation.\n",
    "    \"\"\"\n",
    "    c = np.corrcoef(x, y)[0, 1]\n",
    "    if abs(c) == 1:\n",
    "        c = 0.999999  # avoid division by zero\n",
    "    return -0.5 * np.log(1 - c**2)\n",
    "```\n",
    "\n",
    "The mRMR algorithm iteratively selects the next best feature that maximizes the difference between its relevance to the outputs and its redundancy with the already selected features:\n",
    "\n",
    "$$\n",
    "\\text{mRMR}_j = \\text{Relevance}_j - \\text{Redundancy}_j\n",
    "$$\n",
    "\n",
    "Where, for a candidate feature *j*:\n",
    "- **Relevance**: average MI between the candidate feature *j* and all the output variables\n",
    "- **Redundancy**: average MI between the candidate feature *j* and all the features that have already been selected in previous iterations\n",
    "\n",
    "Here's a sketch of the implementation:\n",
    "```python\n",
    "def greedy_mrmr_selection(X_df, mi_scores):\n",
    "    selected = []\n",
    "    candidates = list(range(X_df.shape[1]))\n",
    "\n",
    "    for _ in range(len(candidates)):\n",
    "        redundancy = ...\n",
    "        mrmr_score = mi_scores[candidates] - redundancy\n",
    "        best = candidates[np.argmax(mrmr_score)]\n",
    "        selected.append(best)\n",
    "        candidates.remove(best)\n",
    "    return selected\n",
    "```\n",
    "\n",
    "To evaluate the performance of the feature subsets selected by mRMR, we performed the following steps:\n",
    "\n",
    "1.  **Iterate through Feature Subset Sizes:** For each subset of selected features, starting from a size of 1 up to $N$ (the total number of extracted features):\n",
    "    * **Create Feature Subset:** Construct a new feature matrix containing only the top $k$ selected features, where $k$ is the current subset size.\n",
    "    * **Build Pipeline:** Create a scikit-learn `Pipeline` that includes a chosen regressor from the described baseline (e.g., `Ridge`, `RandomForestRegressor`).\n",
    "    * **Cross-Validation:** Employ `cross_validate_pipeline` with a $4$-fold strategy to compute the average RMSE across the leave-one-session-out cross-validation folds for this pipeline configuration\n",
    "    * **Calculate Performance Metrics:** Compute the mean and standard deviation of the RMSE values obtained from the cross-validation folds.\n",
    "\n",
    "2.  **Visualize Results:** After evaluating the performance for all feature subset sizes, we generate a plot to visualize the relationship between the number of features and the prediction accuracy. Vertical error bars are plotted around each mean RMSE point to indicate the standard deviation of the RMSE across the different cross-validation folds. This provides a measure of the variability in performance. Each data point in the plot is colored based on the type of the time-domain feature that was added at that specific step in the mRMR selection process (e.g., all 'Mean Absolute Value' (MAV) features have one color, all 'Root Mean Square' (RMS) features another, and so on). \n",
    "\n",
    "This systematic evaluation of mRMR-selected feature subsets aims to identify an effective set of EMG time-domain features that can accurately predict hand joint angles while minimizing redundancy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7836bdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.validation import mutual_info_corr, compute_mi_vector, greedy_mrmr_selection\n",
    "from config.transformers import FeatureSelector\n",
    "from config.utils import plot_mrmr_results\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fadb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation dataset guided\n",
    "\n",
    "# Compute Mutual Info (includes feature extraction)\n",
    "X_df, Y_all, mi_scores, X_sessions = compute_mi_vector(\n",
    "    X_guided_windows_train_val_folds, \n",
    "    Y_guided_labels_train_val_folds, \n",
    "    TimeDomainTransformer(sigma_mpr=0.3)\n",
    "    )\n",
    "\n",
    "# Perform mRMR\n",
    "selected = greedy_mrmr_selection(X_df, mi_scores)\n",
    "\n",
    "models_feat_sel = {\n",
    "    'Kernel Ridge': KernelRidge(\n",
    "        alpha=0.01, \n",
    "        gamma=0.01, \n",
    "        kernel='laplacian'),\n",
    "    'KNN': KNeighborsRegressor(n_neighbors=5),\n",
    "    'Random Forests': RandomForestRegressor(\n",
    "        n_estimators=50, \n",
    "        max_depth=10)\n",
    "}\n",
    "n_features = len(selected)\n",
    "n_sessions = X_sessions.shape[0]\n",
    "CV_results = {}\n",
    "\n",
    "for model_name, model in models_feat_sel.items():\n",
    "    print('---------------------------------------------------------------------------')\n",
    "    print(f'Evaluating mMRM feature selection of the model {model_name} on the guided dataset...')\n",
    "    CV_err_mrmr = np.zeros((n_features, n_sessions))\n",
    "    \n",
    "    for nb_features in range(1, n_features + 1):\n",
    "        selected_indices = selected[:nb_features]\n",
    "        pipeline = Pipeline([\n",
    "            ('select', FeatureSelector(selected_indices)),\n",
    "            ('scale', StandardScaler()),\n",
    "            ('reg', model)\n",
    "        ])\n",
    "        try:\n",
    "            cv_results = cross_validate_pipeline(\n",
    "                pipeline,\n",
    "                X_sessions,\n",
    "                Y_guided_labels_train_val_folds,\n",
    "                metric_fns={'RMSE': RMSE},\n",
    "                n_folds=n_sessions,\n",
    "                verbose=0\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Failed for model: {model_name} | #features: {nb_features}\")\n",
    "            print(e)\n",
    "            break\n",
    "        for fold_id in range(n_sessions):\n",
    "            CV_err_mrmr[nb_features - 1, fold_id] = cv_results[fold_id]['val_RMSE']\n",
    "    \n",
    "    CV_results[model_name] = CV_err_mrmr\n",
    "    \n",
    "    # Plot results for the current model\n",
    "    plot_mrmr_results(\n",
    "        selected,\n",
    "        CV_err_mrmr,\n",
    "        td_feature_names=['MAV', 'RMS', 'VAR', 'STD', 'ZC', 'MPR',\n",
    "                          'MAA', 'WL', 'SSC', 'WA', 'MFL', 'KRT'],\n",
    "        title=f'mRMR Feature Selection - {model_name} - guided dataset'\n",
    "    )\n",
    "\n",
    "# If needed for inspection\n",
    "# Report results (optional - you might not need this if you have the plots)\n",
    "# for model_name, CV_err_mrmr in CV_results.items():\n",
    "#     print(f\"\\nMRMR Feature Selection with {model_name}\")\n",
    "#     for i in range(n_features):\n",
    "#         print(f\"#Features: {i + 1}; CV error = {CV_err_mrmr[i, :].mean():.4f}; std dev = {CV_err_mrmr[i, :].std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1d1e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation dataset freemoves\n",
    "\n",
    "# Compute Mutual Info (includes feature extraction)\n",
    "X_df, Y_all, mi_scores, X_sessions = compute_mi_vector(\n",
    "    X_freemoves_windows_train_val_folds, \n",
    "    Y_freemoves_labels_train_val_folds, \n",
    "    TimeDomainTransformer(sigma_mpr=0.3)\n",
    "    )\n",
    "\n",
    "# Perform mRMR\n",
    "selected = greedy_mrmr_selection(X_df, mi_scores)\n",
    "\n",
    "# Models\n",
    "models_feat_sel = {\n",
    "    'Kernel Ridge': KernelRidge(\n",
    "        alpha=0.01, \n",
    "        gamma=0.01, \n",
    "        kernel='laplacian'),\n",
    "    'KNN': KNeighborsRegressor(n_neighbors=5),\n",
    "    'Random Forests': RandomForestRegressor(\n",
    "        n_estimators=50, \n",
    "        max_depth=10)\n",
    "}\n",
    "n_features = len(selected)\n",
    "n_sessions = X_sessions.shape[0]\n",
    "CV_results = {}\n",
    "\n",
    "for model_name, model in models_feat_sel.items():\n",
    "    print(f\"\\nEvaluating model: {model_name}\")\n",
    "    print('---------------------------------------------------------------------------')\n",
    "    print(f'Evaluating mMRM feature selection of the model {model_name} on the freemoves dataset...')\n",
    "    CV_err_mrmr = np.zeros((n_features, n_sessions))\n",
    "    \n",
    "    for nb_features in range(1, n_features + 1):\n",
    "        selected_indices = selected[:nb_features]\n",
    "        pipeline = Pipeline([\n",
    "            ('select', FeatureSelector(selected_indices)),\n",
    "            ('scale', StandardScaler()),\n",
    "            ('reg', model)\n",
    "        ])\n",
    "        try:\n",
    "            cv_results = cross_validate_pipeline(\n",
    "                pipeline,\n",
    "                X_sessions,\n",
    "                Y_freemoves_labels_train_val_folds,\n",
    "                metric_fns={'RMSE': RMSE},\n",
    "                n_folds=n_sessions,\n",
    "                verbose=0\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Failed for model: {model_name} | #features: {nb_features}\")\n",
    "            print(e)\n",
    "            break\n",
    "        for fold_id in range(n_sessions):\n",
    "            CV_err_mrmr[nb_features - 1, fold_id] = cv_results[fold_id]['val_RMSE']\n",
    "    \n",
    "    CV_results[model_name] = CV_err_mrmr\n",
    "    \n",
    "    # Plot results for the current model\n",
    "    plot_mrmr_results(\n",
    "        selected,\n",
    "        CV_err_mrmr,\n",
    "        td_feature_names=['MAV', 'RMS', 'VAR', 'STD', 'ZC', 'MPR',\n",
    "                          'MAA', 'WL', 'SSC', 'WA', 'MFL', 'KRT'],\n",
    "        title=f'mRMR Feature Selection - {model_name} - freemoves dataset'\n",
    "    )\n",
    "\n",
    "# If needed for inspection\n",
    "# Report results (optional - you might not need this if you have the plots)\n",
    "# for model_name, CV_err_mrmr in CV_results.items():\n",
    "#     print(f\"\\nMRMR Feature Selection with {model_name}\")\n",
    "#     for i in range(n_features):\n",
    "#         print(f\"#Features: {i + 1}; CV error = {CV_err_mrmr[i, :].mean():.4f}; std dev = {CV_err_mrmr[i, :].std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13848a66",
   "metadata": {},
   "source": [
    "We evaluated RMSE across varying numbers of selected features using leave-one-session-out cross-validation. Here are the results near the optimal region (number reported for Kernel Ridge):\n",
    "\n",
    "After visualizing the performance of different feature subset sizes using the plots titled \"mRMR Feature Selection - [Model] - guided dataset\", we examined the results to identify the optimal number of features. As an example, for the Kernel Ridge model, the RMSE across different numbers of selected features using leave-one-session-out cross-validation showed the following trend near the optimal region:\n",
    "\n",
    "```text\n",
    "#Features: 80; CV error = 5.2161; std dev = 0.6287  \n",
    "#Features: 81; CV error = 5.2204; std dev = 0.6276  \n",
    "#Features: 82; CV error = 5.2140; std dev = 0.6210  \n",
    "#Features: 85; CV error = 5.2095; std dev = 0.6255  \n",
    "#Features: 90; CV error = 5.1963; std dev = 0.6175  \n",
    "#Features: 95; CV error = 5.1783; std dev = 0.6114  \n",
    "#Features: 96; CV error = 5.1763; std dev = 0.6115\n",
    "```\n",
    "\n",
    "The results show that after 80 features, additional features provide the addition of more features yields only minimal improvements in the cross-validation RMSE,\n",
    "\n",
    "To integrate feature selection directly into the learning pipeline, we implemented the `TopKMRMRSelector` class as a custom scikit-learn compatible transformer. This enables model training and evaluation without requiring separate preprocessing steps.\n",
    "By setting k=80, we aim to utilize only the top 80 most relevant features as identified by the mRMR algorithm, improving interpretability and reducing the dimensionality the dimensionality of the feature space from the original 96 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bd7b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.transformers import TopKMRMRSelector\n",
    "\n",
    "baseline_mrmr_kr = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', TimeDomainTransformer()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('feature_select', TopKMRMRSelector(k=80)),\n",
    "        ('regressor', KernelRidge(\n",
    "            alpha = 0.01,\n",
    "            gamma = 0.01,\n",
    "            kernel='laplacian'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "baseline_mrmr_knn = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', TimeDomainTransformer()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('feature_select', TopKMRMRSelector(k=80)),\n",
    "        ('regressor', KNeighborsRegressor(\n",
    "            n_neighbors = 5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "baseline_mrmr_rf = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', TimeDomainTransformer()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('feature_select', TopKMRMRSelector(k=80)),\n",
    "        ('regressor', RandomForestRegressor(\n",
    "            n_estimators = 50,\n",
    "            max_depth = 10))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fca7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"baseline_mrmr_kr\" on the guided dataset:')\n",
    "results_guided_baseline_mrmr_kr = cross_validate_pipeline(\n",
    "    pipeline = baseline_mrmr_kr,\n",
    "    X_folds = X_guided_windows_train_val_folds,\n",
    "    Y_folds = Y_guided_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"baseline_mrmr_knn\" on the guided dataset:')\n",
    "results_guided_baseline_mrmr_knn = cross_validate_pipeline(\n",
    "    pipeline = baseline_mrmr_knn,\n",
    "    X_folds = X_guided_windows_train_val_folds,\n",
    "    Y_folds = Y_guided_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"baseline_mrmr_rf\" on the guided dataset:')\n",
    "results_guided_baseline_mrmr_rf = cross_validate_pipeline(\n",
    "    pipeline = baseline_mrmr_rf,\n",
    "    X_folds = X_guided_windows_train_val_folds,\n",
    "    Y_folds = Y_guided_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04d3994",
   "metadata": {},
   "source": [
    "#### 4-fold Leave-One-Session-Out cross-validation of baseline models + mRMR on *freemoves* dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0387a80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"baseline_mrmr_kr\" on the freemoves dataset:')\n",
    "results_freemoves_baseline_mrmr_kr = cross_validate_pipeline(\n",
    "    pipeline = baseline_mrmr_kr,\n",
    "    X_folds = X_freemoves_windows_train_val_folds,\n",
    "    Y_folds = Y_freemoves_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"baseline_mrmr_knn\" on the freemoves dataset:')\n",
    "results_freemoves_baseline_mrmr_knn = cross_validate_pipeline(\n",
    "    pipeline = baseline_mrmr_knn,\n",
    "    X_folds = X_freemoves_windows_train_val_folds,\n",
    "    Y_folds = Y_freemoves_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"baseline_mrmr_rf\" on the freemoves dataset:')\n",
    "results_freemoves_baseline_mrmr_rf = cross_validate_pipeline(\n",
    "    pipeline = baseline_mrmr_rf,\n",
    "    X_folds = X_freemoves_windows_train_val_folds,\n",
    "    Y_folds = Y_freemoves_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a951da",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "We will now turn our attention to the **Principal Component Analysis (PCA)** and how it can be used as a feature selection and dimensionality reduction technique to improve regression performance from EMG time-domain features.\n",
    "\n",
    "We evaluate PCA-based dimensionality reduction by retaining different levels of explained variance, defined by the following thresholds:\n",
    "\n",
    "```python\n",
    "variance_thresholds = np.arange(0.85, 0.991, 0.01)\n",
    "```\n",
    "\n",
    "For each baseline regressor we:\n",
    "- Build a scikit-learn pipeline with the regressor with a PCA step where the number of components is determined by the current variance_threshold\n",
    "- Use cross_validate_pipeline() with a $4$-fold strategy to compute the average RMSE across the leave-one-session-out cross-validation folds for this pipeline configuration\n",
    "- Fit PCA separately to compute the actual number of components retained at that threshold\n",
    "\n",
    "We generate two plots (as subplots in one figure):\n",
    "\n",
    "- **RMSE vs. Variance Retained**: Illustrates how the average cross-validation RMSE changes as we increase the amount of variance retained by PCA\n",
    "- **Components vs. Variance Retained**: Visualizes the dimensionality reduction effect of PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a13d531",
   "metadata": {},
   "source": [
    "#### 4-fold Leave-One-Session-Out cross-validation of baseline models + PCA on *guided* dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54117544",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Evaluaton guided dataset\n",
    "n_sessions, n_windows, n_channels, window_size = X_guided_windows_train_val_folds.shape\n",
    "\n",
    "# Sweep PCA variance thresholds\n",
    "variance_thresholds = np.arange(0.85, 0.991, 0.01)\n",
    "\n",
    "for model_name, model in models_feat_sel.items():\n",
    "    print('---------------------------------------------------------------------------')\n",
    "    print(f'Evaluating PCA feature selection of the model {model_name} on the guided dataset...') \n",
    "    \n",
    "    rmse_scores = []\n",
    "    n_components_used = []\n",
    "\n",
    "    for var in variance_thresholds:\n",
    "        pipeline = Pipeline([\n",
    "            ('td_feat', TimeDomainTransformer()),\n",
    "            ('scale', StandardScaler()),\n",
    "            ('pca', PCA(n_components=float(var), random_state=42)),\n",
    "            ('reg', model)\n",
    "        ])\n",
    "\n",
    "        metric_fns = {'RMSE': RMSE}\n",
    "        results = cross_validate_pipeline(\n",
    "            pipeline,\n",
    "            X_guided_windows_train_val_folds,\n",
    "            Y_guided_labels_train_val_folds,\n",
    "            metric_fns=metric_fns,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Fit once to extract # of components\n",
    "        pipeline.fit(X_guided_windows_train_val_folds.reshape(-1, n_channels, window_size), \n",
    "                     Y_guided_labels_train_val_folds.reshape(-1, 51))\n",
    "        n_comp = pipeline.named_steps['pca'].n_components_\n",
    "\n",
    "        rmse_scores.append(results['avg_val_RMSE'])\n",
    "        n_components_used.append(n_comp)\n",
    "\n",
    "        # print(f\"Variance: {var:.2f}, RMSE: {results['avg_val_RMSE']:.4f}, Components: {n_comp}\")\n",
    "\n",
    "    # Plots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Plot 1: RMSE vs Variance Retained\n",
    "    axs[0].plot(variance_thresholds, rmse_scores, marker='o')\n",
    "    axs[0].set_xlabel(\"PCA Variance Retained\")\n",
    "    axs[0].set_ylabel(\"Cross-Validation RMSE\")\n",
    "    axs[0].set_title(f\"{model_name} - RMSE vs. Variance Retained - guided dataset\")\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    # Plot 2: #Components vs Variance Retained\n",
    "    axs[1].plot(variance_thresholds, n_components_used, marker='s', color='green')\n",
    "    axs[1].set_xlabel(\"PCA Variance Retained\")\n",
    "    axs[1].set_ylabel(\"# PCA Components Retained\")\n",
    "    axs[1].set_title(f\"{model_name} - Components vs. Variance Retained - guided dataset\")\n",
    "    axs[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e75b6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluaton freemoves dataset\n",
    "n_sessions, n_windows, n_channels, window_size = X_freemoves_windows_train_val_folds.shape\n",
    "\n",
    "# Sweep PCA variance thresholds\n",
    "variance_thresholds = np.arange(0.85, 0.991, 0.01)\n",
    "\n",
    "for model_name, model in models_feat_sel.items():\n",
    "    print('---------------------------------------------------------------------------')\n",
    "    print(f'Evaluating PCA feature selection of the model {model_name} on the freemoves dataset...') \n",
    "    \n",
    "    rmse_scores = []\n",
    "    n_components_used = []\n",
    "\n",
    "    for var in variance_thresholds:\n",
    "        pipeline = Pipeline([\n",
    "            ('td_feat', TimeDomainTransformer()),\n",
    "            ('scale', StandardScaler()),\n",
    "            ('pca', PCA(n_components=float(var), random_state=42)),\n",
    "            ('reg', model)\n",
    "        ])\n",
    "\n",
    "        metric_fns = {'RMSE': RMSE}\n",
    "        results = cross_validate_pipeline(\n",
    "            pipeline,\n",
    "            X_freemoves_windows_train_val_folds,\n",
    "            Y_freemoves_labels_train_val_folds,\n",
    "            metric_fns=metric_fns,\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        # Fit once to extract # of components\n",
    "        pipeline.fit(X_freemoves_windows_train_val_folds.reshape(-1, n_channels, window_size), \n",
    "                     Y_freemoves_labels_train_val_folds.reshape(-1, 51))\n",
    "        n_comp = pipeline.named_steps['pca'].n_components_\n",
    "\n",
    "        rmse_scores.append(results['avg_val_RMSE'])\n",
    "        n_components_used.append(n_comp)\n",
    "\n",
    "        # print(f\"Variance: {var:.2f}, RMSE: {results['avg_val_RMSE']:.4f}, Components: {n_comp}\")\n",
    "\n",
    "    # Plots\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "    # Plot 1: RMSE vs Variance Retained\n",
    "    axs[0].plot(variance_thresholds, rmse_scores, marker='o')\n",
    "    axs[0].set_xlabel(\"PCA Variance Retained\")\n",
    "    axs[0].set_ylabel(\"Cross-Validation RMSE\")\n",
    "    axs[0].set_title(f\"{model_name} - RMSE vs. Variance Retained - freemoves dataset\")\n",
    "    axs[0].grid(True)\n",
    "\n",
    "    # Plot 2: #Components vs Variance Retained\n",
    "    axs[1].plot(variance_thresholds, n_components_used, marker='s', color='green')\n",
    "    axs[1].set_xlabel(\"PCA Variance Retained\")\n",
    "    axs[1].set_ylabel(\"# PCA Components Retained\")\n",
    "    axs[1].set_title(f\"{model_name} - Components vs. Variance Retained - freemoves dataset\")\n",
    "    axs[1].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb66677",
   "metadata": {},
   "source": [
    "We observed that RMSE improves only marginally with initial increases in explained variance. However, beyond 0.90, further increases yield almost no RMSE improvements despite adding more components. Choosing much higher variance thresholds adds complexity without substantial accuracy gains, increasing overfitting risk and computation. \n",
    "\n",
    "Therefore, we selected an explained variance threshold near this 0.9 This balances:\n",
    "\n",
    "* **Performance:** Accuracy close to the maximum.\n",
    "* **Dimensionality Reduction:** Fewer features for a simpler model.\n",
    "* **Generalization:** Reduced risk of overfitting.\n",
    "* **Efficiency:** Lower computational cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240fb450",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 0.9\n",
    "\n",
    "baseline_pca_kr = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', TimeDomainTransformer()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('feature_select', PCA(n_components=float(var), random_state=42)),\n",
    "        ('regressor', KernelRidge(\n",
    "            alpha = 0.01,\n",
    "            gamma = 0.01,\n",
    "            kernel='laplacian'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "baseline_pca_knn = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', TimeDomainTransformer()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('feature_select', PCA(n_components=float(var), random_state=42)),\n",
    "        ('regressor', KNeighborsRegressor(\n",
    "            n_neighbors = 5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "baseline_pca_rf = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', TimeDomainTransformer()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('feature_select', PCA(n_components=float(var), random_state=42)),\n",
    "        ('regressor', RandomForestRegressor(\n",
    "            n_estimators = 50,\n",
    "            max_depth = 10))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61c20e8",
   "metadata": {},
   "source": [
    "#### 4-fold Leave-One-Session-Out cross-validation of baseline models + mMRM on *guided* dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd3f5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"baseline_pca_kr\" on the guided dataset:')\n",
    "results_guided_baseline_pca_kr = cross_validate_pipeline(\n",
    "    pipeline = baseline_pca_kr,\n",
    "    X_folds = X_guided_windows_train_val_folds,\n",
    "    Y_folds = Y_guided_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"baseline_pca_knn\" on the guided dataset:')\n",
    "results_guided_baseline_pca_knn = cross_validate_pipeline(\n",
    "    pipeline = baseline_pca_knn,\n",
    "    X_folds = X_guided_windows_train_val_folds,\n",
    "    Y_folds = Y_guided_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"baseline_pca_rf\" on the guided dataset:')\n",
    "results_guided_baseline_pca_rf = cross_validate_pipeline(\n",
    "    pipeline = baseline_pca_rf,\n",
    "    X_folds = X_guided_windows_train_val_folds,\n",
    "    Y_folds = Y_guided_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4132b6d3",
   "metadata": {},
   "source": [
    "#### 4-fold Leave-One-Session-Out cross-validation of baseline models + PCA on *freemoves* dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2350865",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"baseline_pca_kr\" on the freemoves dataset:')\n",
    "results_freemoves_baseline_pca_kr = cross_validate_pipeline(\n",
    "    pipeline = baseline_pca_kr,\n",
    "    X_folds = X_freemoves_windows_train_val_folds,\n",
    "    Y_folds = Y_freemoves_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"baseline_pca_knn\" on the freemoves dataset:')\n",
    "results_freemoves_baseline_pca_knn = cross_validate_pipeline(\n",
    "    pipeline = baseline_pca_knn,\n",
    "    X_folds = X_freemoves_windows_train_val_folds,\n",
    "    Y_folds = Y_freemoves_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"baseline_pca_rf\" on the freemoves dataset:')\n",
    "results_freemoves_baseline_pca_rf = cross_validate_pipeline(\n",
    "    pipeline = baseline_pca_rf,\n",
    "    X_folds = X_freemoves_windows_train_val_folds,\n",
    "    Y_folds = Y_freemoves_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93cca59",
   "metadata": {},
   "source": [
    "# Riemannian Geometry-based pipelines \n",
    "\n",
    "We will now enrich our arsenal of estimators, by developing three new pipelines based on the **Riemannian geometry of covariance matrices**.\n",
    "\n",
    "The baseline pipelines developed above formulate predictions based on simple *time-domain features* extracted from EMG time windows. By contrast, we will now define estimators that formulate predictions based on *covariance matrices* extracted from EMG time windows.\n",
    "\n",
    "As described above, a EMG time window comes in the form of a numpy array `X` of shape `(8, 500)`. By employing the transformer `pyriemann.estimation.Covariances()` from the freely available library `pyriemann`, we can extract a covariance matrix `X_covariance` of shape `(8, 8)`.\n",
    "\n",
    "More precisely, we can think of `X` as a sample $\\mathbf{x} = (x_1,...,x_8)$ from a random vector $\\mathbf{X} = (X_1,...,X_8)$. We can then estimate its covariance $\\text{Cov}(\\mathbf{X}) = \\text{Cov}(X_i, X_j)$ in terms of the *sample covariance matrix* of $\\mathbf{x}$. The result is a $8\\times8$ *symmetric and positive-semidefinite* matrix.\n",
    "\n",
    "8x8 symmetric matrices form a vector space of dimension 36, parametrized by the entries of the upper-triangular part of the matrix. However, the Euclidean geometry of $\\mathbb R^{36}$ is not well-suited to describe distances between covariance matrices. Indeed, the subset of *positive-semidefinite* matrices can be equipped with more appropriate natural geometries, encoded in the form of *Riemannian metrics*. The set of positive-semidefinite 8x8 symmetric matrices, equipped with a Riemannian metric, becomes a 36-dimensional *curved* manifold.\n",
    "\n",
    "The library `pyriemann` exploits these metrics to implement classification and regression models. However, using the intrinsic Riemannian geometry of this manifold can be computationally quite expensive. For this reason, it is convenient to take a first-order approximation of the manifold, by *projecting orthogonally* the covariance matrices to a tangent space. The tangent space at a point is a 36-dimensional *Euclidean* vector space, representing a *linear* approximation of the curved manifold near the given point. Projections to the tangent space thus provide features in the form of vectors in Euclidean space, on which standard regressors and estimators can be used.\n",
    "\n",
    "This projection procedure is implemented in `pyriemann` in the form of a sklearn-compatible transformer. Specifically, an instance of the class `pyriemann.tangentspace.TangentSpace` has:\n",
    "\n",
    "- a `.fit(X, y)` method, where `X` is a numpy array of covariance matrices (shape `(n_matrices, n_channels, n_channels)`), with `y` not used but included for compatibility with sklearn; this method computes and stores internally the Riemannian average of the covariance matrices;\n",
    "\n",
    "- a `.transform(X)` method, which (if called after `.fit()`) takes in input a numpy array of covariance matrices (shape `(n_matrices, n_channels, n_channels)`) and returns the orthogonal projections of these matrices to the tangent space at the Riemannian average (shape `(n_matrices, n_channels * n_channels)`).\n",
    "\n",
    "Our pipelines will follow a common pipeline structure:\n",
    "\n",
    "1. **Covariance Estimation**  \n",
    "   `pyriemann.estimation.Covariances()`  \n",
    "   - Computes the covariance matrix from EMG channels per time window.\n",
    "\n",
    "2. **Tangent Space Projection**  \n",
    "   `pyriemann.tangentspace.TangentSpace(metric='riemann', tsupdate=True)`  \n",
    "   - Projects the SPD matrices onto the tangent space at the Riemannian mean.\n",
    "   - `tsupdate=True` allows updating the tangent space mean at transform time.\n",
    "\n",
    "3. **Feature Scaling**  \n",
    "   `StandardScaler()`\n",
    "   - Standard normalization to mean 0 and unit variance.\n",
    "\n",
    "4. **Regression Model**  \n",
    "   - Varies across pipelines below.\n",
    "\n",
    "As regression model we use again:\n",
    "   \n",
    "   - **Kernel Ridge Regression**\n",
    "\n",
    "   - **K-Nearest Neighbors Regression**\n",
    "\n",
    "   - **Random Forest Regression**\n",
    "\n",
    "The reasons for this particular choice are the same explained in the section describing the baseline pipelines: after some experiments, these models perform reasonably well compare to the others, and they are sufficiently different to ensure good improvement when considered together in an ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e0280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyriemann\n",
    "import pyriemann.regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a06393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Riemannian-based pipelines\n",
    "riem_kr = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', pyriemann.estimation.Covariances()),\n",
    "        ('transformation', pyriemann.tangentspace.TangentSpace(\n",
    "            metric = 'riemann',\n",
    "            tsupdate = True)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', KernelRidge(\n",
    "            alpha = 0.01,\n",
    "            gamma = 0.01,\n",
    "            kernel='laplacian'))\n",
    "    ]\n",
    ")\n",
    "\n",
    "riem_knn = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', pyriemann.estimation.Covariances()),\n",
    "        ('transformation', pyriemann.tangentspace.TangentSpace(\n",
    "            metric = 'riemann',\n",
    "            tsupdate = True)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', KNeighborsRegressor(\n",
    "            n_neighbors = 5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "riem_rf = Pipeline(\n",
    "    [\n",
    "        ('feature_extraction', pyriemann.estimation.Covariances()),\n",
    "        ('transformation', pyriemann.tangentspace.TangentSpace(\n",
    "            metric = 'riemann',\n",
    "            tsupdate = True)),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('regressor', RandomForestRegressor(\n",
    "            n_estimators = 50,\n",
    "            max_depth = 10))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8273ffc3",
   "metadata": {},
   "source": [
    "As for the baseline models, we cross-validate these models on the train-val part of the dataset, by means of **Leave-One-Session-Out 4-fold cross-validation**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b842836b",
   "metadata": {},
   "source": [
    "#### 4-fold Leave-One-Session-Out cross-validation of Riemannian models on *guided* dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae44e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"riem_kr\" on the guided dataset:')\n",
    "results_guided_riem_kr = cross_validate_pipeline(\n",
    "    pipeline = baseline_kr,\n",
    "    X_folds = X_guided_windows_train_val_folds,\n",
    "    Y_folds = Y_guided_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"riem_knn\" on the guided dataset:')\n",
    "results_guided_riem_knn = cross_validate_pipeline(\n",
    "    pipeline = baseline_knn,\n",
    "    X_folds = X_guided_windows_train_val_folds,\n",
    "    Y_folds = Y_guided_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"riem_rf\" on the guided dataset:')\n",
    "results_guided_riem_rf = cross_validate_pipeline(\n",
    "    pipeline = baseline_rf,\n",
    "    X_folds = X_guided_windows_train_val_folds,\n",
    "    Y_folds = Y_guided_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22481b5",
   "metadata": {},
   "source": [
    "#### 4-fold Leave-One-Session-Out cross-validation of Riemannian models on *freemoves* dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc392f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"riem_kr\" on the freemoves dataset:')\n",
    "results_freemoves_riem_kr = cross_validate_pipeline(\n",
    "    pipeline = baseline_kr,\n",
    "    X_folds = X_freemoves_windows_train_val_folds,\n",
    "    Y_folds = Y_freemoves_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"riem_knn\" on the freemoves dataset:')\n",
    "results_freemoves_riem_knn = cross_validate_pipeline(\n",
    "    pipeline = baseline_knn,\n",
    "    X_folds = X_freemoves_windows_train_val_folds,\n",
    "    Y_folds = Y_freemoves_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")\n",
    "\n",
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"riem_rf\" on the freemoves dataset:')\n",
    "results_freemoves_riem_rf = cross_validate_pipeline(\n",
    "    pipeline = baseline_rf,\n",
    "    X_folds = X_freemoves_windows_train_val_folds,\n",
    "    Y_folds = Y_freemoves_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a67a38",
   "metadata": {},
   "source": [
    "# Domain-Adversarial Neural Network (DANN)\n",
    "\n",
    "In EMG-based regression, **inter-session variability** presents a key challenge to generalisation. Signals can differ substantially across recording sessions due to factors such as:\n",
    "\n",
    "- Electrode placement drift\n",
    "- Muscle fatigue or tension variation\n",
    "- Electrical noise or impedance shifts\n",
    "- Skin conductivity changes over time\n",
    "\n",
    "Even when gestures are performed identically, the signal shapes and amplitudes can vary — this is clearly visible when comparing sessions directly.\n",
    "\n",
    "## Empirical check of session variability\n",
    "\n",
    "To substantiate the use of domain-adversarial learning, we first note that our **baseline models exhibit poor cross-session generalisation** showing **one fold significantly underperforming the others**. This suggests that the model overfits to session-specific features.\n",
    "Rather than relying solely on loss metrics, we tried visually highlight this phenomenon. We propose computing a **per-session signal profile summary**, using variance or magnitude-based time features (e.g., mean absolute value, waveform length, etc.) aggregated over all windows and channels. This provides a condensed summary of the **typical signal signature** for each session.\n",
    "\n",
    "**Suggested visualisation:** - TEMPORARY\n",
    "- A grid of plots — one per session — each showing a compact summary (e.g., channel-wise MAV or RMS curves over time)\n",
    "- This allows direct visual comparison of **how sessions differ globally**, while avoiding the complexity of deeper classifiers\n",
    "\n",
    "Such a summary figure helps confirm that:\n",
    "- Each session indeed has a **distinct signal signature**\n",
    "- Domain shifts are large enough to justify using a **domain-adversarial approach**\n",
    "\n",
    "In this context, DANN becomes essential: it penalises representations that retain session identity and enforces learning of **shared signal structure**, not session-specific noise. Rather than rely on classical regularisation alone, we use **domain-adversarial training** to penalise representations that encode session-specific information.\n",
    "\n",
    "The core idea is: \n",
    "- If a feature extractor allows a domain classifier to easily identify which session a signal comes from, then it is learning features that are not session-invariant.  \n",
    "- DANN flips the gradients from the domain classifier to *discourage* such behaviour.\n",
    "\n",
    "By integrating a **domain classifier and gradient reversal layer**, we force the network to **learn features that generalise across sessions**, leading to more robust predictions even on unseen recordings.\n",
    "\n",
    "According to the literature CITATION OF PAPER convolutional Neural Networks (CNNs) are well-suited to modelling **temporal and spatial patterns** in time-series data like EMG. The reasons are:\n",
    "\n",
    "- They can detect **local patterns** (e.g. bursts or waves) that correspond to muscle activation\n",
    "- They **share weights** across time, ensuring translation-invariance\n",
    "- They efficiently extract features over long time windows (e.g. 500ms) without exploding parameter counts\n",
    "\n",
    "This makes CNNs particularly effective for EMG feature extraction, especially when combined with DANN to learn session-agnostic representations.\n",
    "\n",
    "## DANN Architecture\n",
    "\n",
    "The DANN model used in this project consists of three key components:\n",
    "\n",
    ">  ### 1. Feature Extractor (CNN)\n",
    "> \n",
    "> - **Purpose:** Converts the raw multi-channel EMG signal into a compact latent representation that captures relevant temporal features.\n",
    "> - **Input:** A tensor of shape `(batch_size, channels, time)`, typically including the raw signal and its first derivative.\n",
    "> - **Architecture:** A stack of 1D convolutional layers with ReLU activation, batch normalization, dropout, and pooling.\n",
    "> - **Output:** A feature vector of fixed size (e.g. 128-dim), serving as the input to both the regressor and the domain classifier.\n",
    "> \n",
    "> This block is responsible for **capturing spatial and temporal correlations** in EMG signals while being general enough to apply across recording sessions.\n",
    "> \n",
    "> \n",
    "> ### 2. Regressor Head\n",
    "> \n",
    "> - **Purpose:** Predicts the 51-dimensional vector of joint angles from the extracted feature representation.\n",
    "> - **Input:** The latent feature vector from the feature extractor.\n",
    "> - **Output:** A continuous prediction for each joint angle.\n",
    "> \n",
    "> While this module is evaluated using **Mean Squared Error (MSE)** on joint angle predictions, it is not trained in isolation — it is optimised jointly as part of a broader loss function that includes domain adaptation objectives.\n",
    "> \n",
    "> \n",
    "> ### 3. Domain Classifier + Gradient Reversal Layer (GRL)\n",
    "> \n",
    "> - **Purpose:** Attempts to classify which session the input signal came from.\n",
    "> - **Architecture:** A lightweight classifier (e.g., MLP) producing a probability distribution over the session domain labels.\n",
    "> - **Gradient Reversal Layer (GRL):** During backpropagation, the GRL inverts the gradient signal coming from the domain classifier. This encourages the feature extractor to **remove session-specific information**.\n",
    "> \n",
    "> By penalising features that allow easy domain classification, the feature extractor is encouraged to learn **session-invariant representations**, improving generalisation.\n",
    "\n",
    "### Training Strategy\n",
    "\n",
    "The DANN model is trained using a **composite loss function** that balances prediction accuracy and domain invariance. Specifically, the model minimises the following total loss:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{total}} = \\mathcal{L}_{\\text{reg}} + \\lambda \\cdot \\mathcal{L}_{\\text{domain}} - \\gamma \\cdot \\mathcal{H}(\\text{domain\\_pred})\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\mathcal{L}_{\\text{reg}}$: Mean Squared Error (MSE) between predicted and true joint angles  \n",
    "- $\\mathcal{L}_{\\text{domain}}$: Cross-entropy loss on predicted session (domain)  \n",
    "- $\\mathcal{H}$: Shannon entropy of the domain prediction distribution (optional regulariser)  \n",
    "- $\\lambda$: Adversarial weighting factor (annealed from 0 to 1)  \n",
    "- $\\gamma$: Entropy regularisation coefficient (typically small, e.g. 0.05–0.1)\n",
    "\n",
    "At each iteration during training:\n",
    "\n",
    "1. The EMG input $x$ is passed through the **feature extractor**, producing latent features.\n",
    "2. These features are passed to:\n",
    "   - The **regressor**, which outputs joint angle predictions $\\hat{y}$\n",
    "   - The **domain classifier**, via a **Gradient Reversal Layer**, which outputs session prediction logits\n",
    "3. The three loss components are computed and combined into the total loss.\n",
    "4. A single backward pass updates all parameters jointly, with the GRL flipping gradients flowing into the feature extractor from the domain classifier.\n",
    "\n",
    "The python implementation od the DANN model is done creating compatible torch modules: \n",
    "\n",
    "- `class DANNModel(nn.Module)`: Defines the core Domain-Adversarial Neural Network architecture. It encapsulates the three key submodules:\n",
    "\n",
    "   1. `ConvFeatureExtractor`:  \n",
    "      CNN-based block transforming EMG windows of shape `(batch_size, 8, 500)` into compact 128-dim features.\n",
    "   2. `RegressorHead`:  \n",
    "      Fully connected layers that map latent features to the 51 joint-angle outputs.\n",
    "   3. `DomainDiscriminator`:  \n",
    "      Lightweight classifier (MLP) to predict session identity. Connected via a **Gradient Reversal Layer (GRL)** to encourage domain-invariant feature learning.\n",
    "\n",
    "<!-- **Key Parameters:**\n",
    "\n",
    "- `lambda_grl` *(float)*: Weight of gradient reversal in the adversarial loss. Passed at each forward pass.\n",
    "- `num_domains` *(int)*: Number of different session labels for the domain classifier.\n",
    "- `output_dim` *(int)*: Number of regression outputs (default is 51 joint angles). -->\n",
    "\n",
    "- `class DANNTrainer`: Manages the full training loop for DANN, including:\n",
    "\n",
    "   - Gradient reversal and joint optimisation of regression + domain losses\n",
    "   - Cross-session early stopping\n",
    "   - Composite loss:  \n",
    "   $$\n",
    "   \\mathcal{L}_{\\text{total}} = \\mathcal{L}_{\\text{reg}} + \\lambda \\cdot \\mathcal{L}_{\\text{domain}} - \\gamma \\cdot \\mathcal{H}\n",
    "   $$\n",
    "\n",
    "<!-- **Key Arguments:**\n",
    "\n",
    "- `model` *(nn.Module)*: Must follow the DANN interface (e.g., return both regression and domain outputs).\n",
    "- `train_loader`, `val_loader`: PyTorch `DataLoader` objects for training/validation.\n",
    "- `lambda_grl`: Strength of the gradient reversal loss component (annealed across epochs).\n",
    "- `gamma_entropy`: Optional entropy regularisation to encourage uniform domain predictions.\n",
    "- `max_epochs`, `patience`: Control training loop and early stopping.\n",
    "- `device`: Typically `\"cuda\"` or `\"cpu\"`.\n",
    "\n",
    "**Core Methods:**\n",
    "\n",
    "- `.train()`: Trains with early stopping on validation RMSE.\n",
    "- `.predict(data_loader)`: Forward pass on new data.\n",
    "- `.evaluate()`: Computes RMSE on validation set.\n",
    "- `.evaluate_domain_on_train()`: Returns accuracy of domain predictions on training set — useful to diagnose invariance. -->\n",
    "\n",
    "To be consistent with our cross-validation strategy, we also created a `cross_validate_dann` function to automates the session-wise **leave-one-session-out** cross-validation for DANN training. The function works in following way:\n",
    "\n",
    "1. Splits the 5 sessions into 4 training and 1 validation.\n",
    "2. Constructs appropriate session IDs for domain classification.\n",
    "3. Trains a new `DANNModel` per fold with fresh `DANNTrainer`.\n",
    "4. Aggregates RMSE scores across folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68acdcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.dann import DataLoader, DANNModel, DANNTrainer, DANNWindowTensor, DANNRegressor, DANNConfig, DANNRunner, torch, TemporalDANNModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd50358",
   "metadata": {},
   "source": [
    "#### 4-fold Leave-One-Session-Out cross-validation of DANN model on *guided* dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce9c2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_guided = DANNConfig(\n",
    "    batch_size=256,\n",
    "    max_epochs=40,\n",
    "    patience=10,\n",
    "    learning_rate=1e-3,\n",
    "    lambda_grl=1.0,\n",
    "    gamma_entropy=0.05,\n",
    "    num_domains=4,\n",
    "    output_dim=51,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    verbose=1  # verbose=2 for epoch logs\n",
    ")\n",
    "\n",
    "\n",
    "runner_guided = DANNRunner(\n",
    "    model_class=lambda **kwargs: DANNModel(**kwargs),\n",
    "    dataset_class=DANNWindowTensor,\n",
    "    config=config_guided\n",
    ")\n",
    "\n",
    "results_guided_dann = runner_guided.cross_validate(\n",
    "    X_guided_windows_train_val_folds, \n",
    "    Y_guided_labels_train_val_folds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e4740c",
   "metadata": {},
   "source": [
    "#### 4-fold Leave-One-Session-Out cross-validation of DANN model on *freemoves* dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccd1dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_freemoves = DANNConfig(\n",
    "    batch_size=256,\n",
    "    max_epochs=40,\n",
    "    patience=10,\n",
    "    learning_rate=1e-3,\n",
    "    lambda_grl=1.0,\n",
    "    gamma_entropy=0.05,\n",
    "    num_domains=4,\n",
    "    output_dim=51,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    verbose=1  # verbose=2 for epoch logs\n",
    ")\n",
    "\n",
    "\n",
    "runner_freemoves = DANNRunner(\n",
    "    model_class=lambda **kwargs: DANNModel(**kwargs),\n",
    "    dataset_class=DANNWindowTensor,\n",
    "    config=config_freemoves\n",
    ")\n",
    "\n",
    "results_freemoves_dann = runner_freemoves.cross_validate(\n",
    "    X_freemoves_windows_train_val_folds, \n",
    "    Y_freemoves_labels_train_val_folds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344cdead",
   "metadata": {},
   "source": [
    "# TempDANN\n",
    "\n",
    "TO DO ......."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1fbc34",
   "metadata": {},
   "source": [
    "#  Ensemble\n",
    "\n",
    "Design and implement two ensembling strategies that combine the predictions of all individual regression models you implemented, each independently trained on distinct feature representations of the EMG signals. The two required ensembling approaches are the following:\n",
    "- Compute the average of the predicted values\n",
    "- Use a meta-learner strategy (often referred to as stacking), in which a separate model—trained on the outputs of the base learners—generates the ensemble prediction\n",
    "For each ensemble strategy, compare and document the ensemble’s regression performance against each of its constituent base models using consistent regression metrics. Additionally, for the metalearner strategy, determine and discuss the relative contribution of each base model to the final ensemble prediction. Discuss how the bias-variance tradeoff relates to the observed (or expected) evolution of performance.\n",
    "\n",
    "## Ensemble Method: Voting Regressor\n",
    "\n",
    "To enhance the robustness and accuracy of our predictions, we employ an ensemble learning technique using a Voting Regressor. The idea behind ensembling is simple: different models may capture different aspects of the signal, and by aggregating their predictions, we can reduce variance, mitigate individual model weaknesses, and improve overall robustness and accuracy.\n",
    "\n",
    "We implement a **Voting Regressor**, which performs prediction by taking a **weighted average** of the outputs of multiple base regressors. If we denote the predictions of $M$ models as $\\hat{y}_1, \\hat{y}_2, \\ldots, \\hat{y}_M$, then the final ensemble prediction is computed as:\n",
    "\n",
    "$$\n",
    "\\hat{y}_{\\text{ensemble}} = \\frac{1}{M} \\sum_{m=1}^{M} \\hat{y}_m\n",
    "$$]\n",
    "\n",
    "Our implementation of the Voting Regressor is as a custom scikit-learn-compatible class `VotingRegressor`, which fits each constituent baseline pipeline individually and then combines their predictions at inference time. The ensemble combines both time-domain and Riemannian geometry-based pipelines. Each included model brings a different inductive bias or mathematical structure to the task:\n",
    "\n",
    "* `baseline_kr`: Kernel Ridge Regression applied to time-domain features.\n",
    "* `baseline_rf`: Random Forest Regression applied to time-domain features.\n",
    "* `riem3`, `riem4`: Riemannian geometry-based pipelines utilizing tangent space projections of covariance matrices.\n",
    "\n",
    "These pipelines were chosen based on their individual performance and the diversity of their approaches to ensure a well-rounded ensemble.\n",
    "\n",
    "The final ensemble is instantiated as:\n",
    "```python\n",
    "voting_estimator = VotingRegressor(\n",
    "    estimators = [\n",
    "        baseline_guided_kr,\n",
    "        baseline_guided_rf,\n",
    "        riem3,\n",
    "        riem4\n",
    "    ]\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eb2240",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.regressors import VotingRegressor\n",
    "\n",
    "# TO CHECK: ENSEMBLE VOTING CODE\n",
    "\n",
    "voting_estimator = VotingRegressor(\n",
    "    estimators = [\n",
    "        baseline_kr,\n",
    "        baseline_knn,\n",
    "        baseline_rf,\n",
    "        riem_kr,\n",
    "        riem_knn,\n",
    "        riem_rf\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e51046",
   "metadata": {},
   "source": [
    "#### 4-fold Leave-One-Session-Out cross-validation of Voting Regressor model on *guided* dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e32785",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"voting_estimator\" on the guided dataset:')\n",
    "results_guided_voting = cross_validate_pipeline(\n",
    "    pipeline = voting_estimator,\n",
    "    X_folds = X_guided_windows_train_val_folds,\n",
    "    Y_folds = Y_guided_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07245ac",
   "metadata": {},
   "source": [
    "#### 4-fold Leave-One-Session-Out cross-validation of Voting Regressor model on *freemoves* dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675e6cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"voting_estimator\" on the freemoves dataset:')\n",
    "results_freemoves_voting = cross_validate_pipeline(\n",
    "    pipeline = voting_estimator,\n",
    "    X_folds = X_freemoves_windows_train_val_folds,\n",
    "    Y_folds = Y_freemoves_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d907c1b5",
   "metadata": {},
   "source": [
    "## Ensemble Method: Stackig Regressor\n",
    "\n",
    "TO DO: ENSEMBLE STACKING DESCRIPTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdaa6e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.regressors import StackingRegressor\n",
    "\n",
    "stacking_estimator = StackingRegressor(\n",
    "    estimators = [\n",
    "        baseline_kr,\n",
    "        baseline_knn,\n",
    "        baseline_rf,\n",
    "        riem_kr,\n",
    "        riem_knn,\n",
    "        riem_rf\n",
    "    ],\n",
    "    end_estimator = RandomForestRegressor(\n",
    "        n_estimators = 50,\n",
    "        max_depth = 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36364074",
   "metadata": {},
   "source": [
    "#### 4-fold Leave-One-Session-Out cross-validation of Stacking Regressor model on *guided* dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff0b85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"stacking_estimator\" on the guided dataset:')\n",
    "results_guided_voting = cross_validate_pipeline(\n",
    "    pipeline = stacking_estimator,\n",
    "    X_folds = X_guided_windows_train_val_folds,\n",
    "    Y_folds = Y_guided_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362b27dd",
   "metadata": {},
   "source": [
    "#### 4-fold Leave-One-Session-Out cross-validation of Stacking Regressor model on *freemoves* dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed55fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('---------------------------------------------------------------------------')\n",
    "print('Cross-Validation of the pipeline \"stacking_estimator\" on the freemoves dataset:')\n",
    "results_freemoves_voting = cross_validate_pipeline(\n",
    "    pipeline = stacking_estimator,\n",
    "    X_folds = X_freemoves_windows_train_val_folds,\n",
    "    Y_folds = Y_freemoves_labels_train_val_folds,\n",
    "    metric_fns = {'RMSE': RMSE, 'NMSE': NMSE},\n",
    "    n_folds = 4,\n",
    "    # verbose 0: silent mode; verbose 1: only average across folds values printed; verbose 2: results of all folds printed\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb84ef29",
   "metadata": {},
   "source": [
    "#  Extra\n",
    "\n",
    "## Filter\n",
    "\n",
    "## Cross validation full data\n",
    "\n",
    "## Fancy 3D plots\n",
    "\n",
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2336db44",
   "metadata": {},
   "source": [
    "# Final models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
